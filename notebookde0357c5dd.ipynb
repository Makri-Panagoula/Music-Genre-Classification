{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7766391,"sourceType":"datasetVersion","datasetId":4542817},{"sourceId":7766402,"sourceType":"datasetVersion","datasetId":4542827},{"sourceId":7766406,"sourceType":"datasetVersion","datasetId":4542831},{"sourceId":7768200,"sourceType":"datasetVersion","datasetId":4544185}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  **Import Libraries & Install Packages & Initialize Structures for Preprocessing:**","metadata":{}},{"cell_type":"code","source":"!pip install demoji\n!pip install emoji\n!pip install emot\n!pip install googletrans==4.0.0-rc1\n!pip install Unidecode\n!pip install greek-stemmer-pos\n!pip install spacy \n!pip install torch\n!pip install optuna\n!pip install torchmetrics\n!pip install transformers\n!python -m spacy download el_core_news_sm\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport pandas as pd\nimport logging\nimport csv\nimport torch\nimport os\nimport optuna\nimport spacy\nimport nltk\nimport re\nimport string\nimport emoji\nimport demoji\nimport emot\nimport itertools\nimport gensim\nimport multiprocessing\nimport numpy as np\nimport unicodedata as ud\nimport random\nimport torch.nn as nn\nimport torch.optim as optim\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport optuna.visualization as vis\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence,pad_packed_sequence\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader,Dataset\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom googletrans import Translator\nfrom emot.emo_unicode import EMOTICONS_EMO\nfrom sklearn.metrics import precision_score, recall_score\nfrom flashtext import KeywordProcessor\nfrom sklearn.linear_model import LogisticRegression\nfrom greek_stemmer import stemmer\nfrom spacy.lang.el.examples import sentences \nfrom gensim.models import Word2Vec\nfrom gensim.models.phrases import Phrases, Phraser\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom transformers import  AutoTokenizer, AutoModel\n\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:00:06.613818Z","iopub.execute_input":"2024-03-08T14:00:06.614418Z","iopub.status.idle":"2024-03-08T14:04:01.694911Z","shell.execute_reply.started":"2024-03-08T14:00:06.614385Z","shell.execute_reply":"2024-03-08T14:04:01.693763Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting demoji\n  Downloading demoji-1.1.0-py3-none-any.whl.metadata (9.2 kB)\nDownloading demoji-1.1.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: demoji\nSuccessfully installed demoji-1.1.0\nRequirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (2.10.1)\nCollecting emot\n  Downloading emot-3.1-py3-none-any.whl.metadata (396 bytes)\nDownloading emot-3.1-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: emot\nSuccessfully installed emot-3.1\nCollecting googletrans==4.0.0-rc1\n  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\nCollecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading hstspreload-2024.3.1-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\nCollecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\nCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\nCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\nCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\nCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\nCollecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\nDownloading httpx-0.13.3-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading hstspreload-2024.3.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\nDownloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: googletrans\n  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=91d66afd061666604d4b958014cc85aa47b97f7aa7a9d5fa57b7b2d912be09ee\n  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\nSuccessfully built googletrans\nInstalling collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n  Attempting uninstall: h11\n    Found existing installation: h11 0.14.0\n    Uninstalling h11-0.14.0:\n      Successfully uninstalled h11-0.14.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n  Attempting uninstall: httpcore\n    Found existing installation: httpcore 1.0.4\n    Uninstalling httpcore-1.0.4:\n      Successfully uninstalled httpcore-1.0.4\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.27.0\n    Uninstalling httpx-0.27.0:\n      Successfully uninstalled httpx-0.27.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\njupyterlab 4.1.2 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\njupyterlab 4.1.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.3.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\nRequirement already satisfied: Unidecode in /opt/conda/lib/python3.10/site-packages (1.3.8)\nCollecting greek-stemmer-pos\n  Downloading greek_stemmer_pos-1.1.2-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from greek-stemmer-pos) (8.0.1)\nCollecting pytest-cov (from greek-stemmer-pos)\n  Downloading pytest_cov-4.1.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (21.3)\nRequirement already satisfied: pluggy<2.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (1.2.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (2.0.1)\nCollecting coverage>=5.2.1 (from coverage[toml]>=5.2.1->pytest-cov->greek-stemmer-pos)\n  Downloading coverage-7.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest->greek-stemmer-pos) (3.1.1)\nDownloading greek_stemmer_pos-1.1.2-py3-none-any.whl (19 kB)\nDownloading pytest_cov-4.1.0-py3-none-any.whl (21 kB)\nDownloading coverage-7.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: coverage, pytest-cov, greek-stemmer-pos\nSuccessfully installed coverage-7.4.3 greek-stemmer-pos-1.1.2 pytest-cov-4.1.0\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.5.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.2)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.1)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.1.2+cpu)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.10.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nCollecting el-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/el_core_news_sm-3.7.0/el_core_news_sm-3.7.0-py3-none-any.whl (12.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from el-core-news-sm==3.7.0) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->el-core-news-sm==3.7.0) (2.1.3)\nInstalling collected packages: el-core-news-sm\nSuccessfully installed el-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('el_core_news_sm')\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"#Read the datasets\ntrain_df = pd.read_csv(\"/kaggle/input/training/train_set.csv\")\nval_df = pd.read_csv(\"/kaggle/input/validation/valid_set.csv\")\n\n#Concatenate train_df and val_df since they are the only ones that have a label and later split into train,validation and test set\ndf = pd.concat([train_df, val_df], ignore_index=True)\n#Remove rows that don't have acceptable values \nacceptable_labels = ['POSITIVE','NEGATIVE','NEUTRAL']\ndf = df[df['Sentiment'].isin(acceptable_labels)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:04:01.697310Z","iopub.execute_input":"2024-03-08T14:04:01.698510Z","iopub.status.idle":"2024-03-08T14:04:02.224882Z","shell.execute_reply.started":"2024-03-08T14:04:01.698466Z","shell.execute_reply":"2024-03-08T14:04:02.223702Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"#  Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"#Creating a simple function to roughly convert most greeklish to greek\ngreek_alphabet = 'ΑαΒβΓγΔδΕεΖζΗηΘθΙιΚκΛλΜμΝνΞξΟοΠπΡρΣσςΤτΥυΦφΧχΨψΩω'\nlatin_alphabet = 'AaBbGgDdEeZzHhJjIiKkLlMmNnXxOoPpRrSssTtUuFfQqYyWw'\ngreeklish_to_greek = str.maketrans(latin_alphabet,greek_alphabet)\n\n#Creating a Keyword Processor for converting emojis and emoticons to their greek meaning\ntranslator = Translator()\nemoticons = {**EMOTICONS_EMO}\nkp_emojis = KeywordProcessor()\n#We will create a dictionary that maps each emoticon in each equivalent greek word. We will repeat the same for emojis\nfor emoticon,value in emoticons.items() :\n    try :\n       greek_value = translator.translate(value.replace(\":\",\"\").replace(\"_\",\" \").strip(), src='en', dest='el').text\n    except :\n        greek_value = \"\"\n        \n    kp_emojis.add_keyword(emoticon, greek_value)\n    \n# Load the Greek language model for spacy\nnlp = spacy.load('el_core_news_sm')\n\n#More Greek stopwords from our custom made file\nwith open('/kaggle/input/stopwords/Greek-Stopwords.txt', 'r') as file:\n    # Read lines and remove '\\n' from each line\n    more_stopwords = [line.strip() for line in file.readlines()]\n    \nstops = set(stopwords.words('greek')).union(more_stopwords)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:04:02.228434Z","iopub.execute_input":"2024-03-08T14:04:02.229250Z","iopub.status.idle":"2024-03-08T14:04:21.257912Z","shell.execute_reply.started":"2024-03-08T14:04:02.229207Z","shell.execute_reply":"2024-03-08T14:04:21.256710Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class DataPreprocessing(BaseEstimator, TransformerMixin):\n    \n    def remove_tags(self, text):\n        return re.sub('@.*? ', '',text)\n    \n    def remove_urls(self, text):\n        return re.sub(r'http.?://[^\\s]+[\\s]?', '',text)\n    \n    def emoji_to_word(self, text):\n        #Get the map of emojis and their meaning in current text\n        emojis = demoji.findall(text)\n        #Convert the meaning to greek and add pair to keyword processor if it doesn't already exists\n        for emoji,value in emojis.items():\n            try :\n               greek_value = translator.translate(value.replace(\":\",\"\").replace(\"_\",\" \").strip(), src='en', dest='el').text\n            except :\n                greek_value = \"\"  \n                \n            # We replace emojis and emoticons with their corresponding greek words\n            kp_emojis.add_keyword(emoji, greek_value) \n            \n        return kp_emojis.replace_keywords(text)\n    \n    def remove_emoji(self, text):\n        emoji_pattern = re.compile(\"[\"\n                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                                   u\"\\U00002702-\\U000027B0\"\n                                   u\"\\U000024C2-\\U0001F251\"\n                                   \"]+\", flags=re.UNICODE)\n        return emoji_pattern.sub(r'', text)\n    \n    def remove_hashtags(self,text):\n        #We remove the string following the hashtag\n        words = text.split()\n        return ' '.join(word for word in words if not word.startswith('#'))\n    \n    def remove_punctuation(self, text):\n        # We leave a space in the place of every punctuation symbol to avoid mistaken concatenation between words\n        greek_punc = punctuation + '«' +'»'+'’'\n        trantab = str.maketrans(greek_punc, len(greek_punc)*' ')  \n        return text.translate(trantab)\n    \n    def remove_accents(self, text):\n        d = {ord('\\N{COMBINING ACUTE ACCENT}'):None}\n        return ud.normalize('NFD',text).translate(d)\n    \n    def remove_digits(self, input_text):\n        return re.sub('\\d+', '', input_text)    \n    \n    def remove_stopwords(self, text):\n        words = text.split() \n        #We remove strings that aren't words as well as stop words\n        filtered_words = [word for word in words if (word not in stops) and len(word) > 1] \n        return \" \".join(filtered_words) \n    \n    def to_lower(self, text):\n        return text.lower()\n    \n    def convert_greeklish(self, text):\n        return text.translate(greeklish_to_greek)\n    \n    def remove_greeklish(self,text):\n        # We replace every non-greek word with an empty string\n        latin_pattern = r'\\b[a-zA-Z]+\\b'\n        return re.sub(latin_pattern, '', text)\n        \n    def stemming(self,text):\n        words = text.split() \n        stemmed_words = [stemmer.stem_word(word,'VB') for word in words]\n        return \" \".join(stemmed_words)\n    \n    def lemmatization(self,text):\n        doc = nlp(text)\n        return ' '.join([token.lemma_ for token in doc])\n    \n    def remove_redundant(self,text):\n        words = text.split()  \n        cleaned_words = []\n\n        for word in words:\n            cleaned_word = word.rstrip('ς')  # Remove redundant ς characters from the end of the word\n            cleaned_words.append(cleaned_word)\n\n        return  ' '.join(cleaned_words) \n    \n    def fit(self, X, y=None, **fit_params):\n        return self   \n    \n    def transform(self, X, **transform_params):\n        \n        filtered_X = X.apply(self.remove_tags).apply(self.remove_urls)\n        \n        if 'remove_emojis' in transform_params:\n            filtered_X = filtered_X.apply(self.remove_emoji)\n        else :\n            filtered_X = filtered_X.apply(self.emoji_to_word)\n            \n        if 'remove_hashtags' in transform_params:\n            filtered_X = filtered_X.apply(self.remove_hashtags)            \n            \n        filtered_X = filtered_X.apply(self.remove_punctuation).apply(self.remove_greeklish)\n        \n        if 'remove_digits' in transform_params:\n            filtered_X = filtered_X.apply(self.remove_digits)\n            \n        if 'remove_greeklish' in transform_params:\n            filtered_X = filtered_X.apply(self.remove_greeklish)   \n        else :\n            filtered_X = filtered_X.apply(self.convert_greeklish)   \n            \n        if 'lemmatization'in transform_params:\n            filtered_X = filtered_X.apply(self.lemmatization)\n            \n        elif 'stemming'in transform_params:\n            filtered_X = filtered_X.apply(self.stemming)\n        \n        filtered_X = filtered_X.apply(self.remove_accents).apply(self.to_lower).apply(self.remove_redundant).apply(self.remove_stopwords)\n        return filtered_X  \n    \n    def fit_transform(self, X, **transform_params):\n        # Fit phase\n        self.fit(X)\n\n        # Transform phase using the provided transform_params\n        return self.transform(X, **transform_params)  ","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:04:21.261228Z","iopub.execute_input":"2024-03-08T14:04:21.261692Z","iopub.status.idle":"2024-03-08T14:04:21.289422Z","shell.execute_reply.started":"2024-03-08T14:04:21.261643Z","shell.execute_reply":"2024-03-08T14:04:21.288544Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing & Stats:**","metadata":{}},{"cell_type":"code","source":"#Data Cleaning\nProcessor = DataPreprocessing()\nparams = {'remove_emojis' : 'y','lemmatization': 'y'}\ndf['Text'] = Processor.fit_transform(df['Text'],**params)\n\n# Filter out rows with non-zero token count in the 'Text' column\nempty_text = df[df['Text'].apply(lambda x: len(x.split()) == 0)].index\n\n#Reset the index to make it consistent after removing rows\ndf.drop(empty_text, inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\nlabels = df['Sentiment']\nfinal_df = df.drop('Sentiment', axis=1)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Running in \",device)\n\nlabels_to_int = {\"POSITIVE\" : 0, \"NEGATIVE\" : 1 , \"NEUTRAL\" : 2}\nint_to_labels = {0 : \"POSITIVE\", 1 : \"NEGATIVE\", 2 : \"NEUTRAL\"}\nlabels = labels.apply(lambda x: labels_to_int.get(x))\nlabels_tensor = torch.tensor(labels, device=device)\n\n#Read Actual Test Set \ntest_df = pd.read_csv(\"/kaggle/input/testset/test_set.csv\")\n\n#Perform best Data Preprocessing Technique \nparams = {'remove_emojis' : 'y','lemmatization': 'y'}\ntest_df['Text'] = Processor.fit_transform(test_df['Text'],**params)\n\n# Filter out rows with non-zero token count in the 'Text' column\nempty_text = test_df[test_df['Text'].apply(lambda x: len(x.split()) == 0)].index\n\n# Reset the index to make it consistent after removing rows\ntest_df.drop(empty_text, inplace=True)\n\n#Analysing words' frequency and statistics\nwords = nltk.tokenize.word_tokenize(df['Text'].str.cat(sep=' '))\nword_dist = nltk.FreqDist(words)\nmost_common = pd.Series(dict(word_dist.most_common(20)))\nfig, ax = plt.subplots(figsize=(10,10))\nall_plot = sns.barplot(x=most_common.index, y=most_common.values, ax=ax)\nplt.xticks(rotation=30)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:04:21.291091Z","iopub.execute_input":"2024-03-08T14:04:21.291502Z","iopub.status.idle":"2024-03-08T14:13:45.447502Z","shell.execute_reply.started":"2024-03-08T14:04:21.291473Z","shell.execute_reply":"2024-03-08T14:13:45.446128Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Running in  cpu\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18, 19]),\n [Text(0, 0, 'τσιπρα'),\n  Text(1, 0, 'μητσοτακη'),\n  Text(2, 0, 'νδ'),\n  Text(3, 0, 'συριζα'),\n  Text(4, 0, 'κκε'),\n  Text(5, 0, 'εκλογες2019'),\n  Text(6, 0, '2019'),\n  Text(7, 0, 'κανω'),\n  Text(8, 0, 'σκαι'),\n  Text(9, 0, 'πασοκ'),\n  Text(10, 0, 'νεο'),\n  Text(11, 0, 'κιναλ'),\n  Text(12, 0, 'εκλογη'),\n  Text(13, 0, 'εκλογε'),\n  Text(14, 0, 'μπορω'),\n  Text(15, 0, 'αλεξη'),\n  Text(16, 0, 'ελλαδα'),\n  Text(17, 0, 'συνεντευξη'),\n  Text(18, 0, 'λεγω'),\n  Text(19, 0, 'θελω')])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA1AAAANZCAYAAAABFN/5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLuklEQVR4nOzdd3yN5//H8c8JtSUxKhFi1EoQKzFij1RiU9SIUXu2VEtRVdSqVZTSapW2KB3aojXKV7X2qFqlaq/EV4NYiYzP7w+/c39zC3UhS/t6Ph4ebc59nXNfZ93nfl/rdqiqCgAAAADggVxSuwIAAAAA8KQgQAEAAACAIQIUAAAAABgiQAEAAACAIQIUAAAAABgiQAEAAACAIQIUAAAAABhKn9oVSE3x8fFy/vx5yZ49uzgcjtSuDgAAAIBUoqpy7do18fLyEheX+/cz/asD1Pnz58Xb2zu1qwEAAAAgjThz5ozkz5//vtv/1QEqe/bsInLnRXJ1dU3l2gAAAABILZGRkeLt7W1lhPv5Vwco57A9V1dXAhQAAACAB07tYREJAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQ+lTuwJpyX/nfJZq+366T4dU2zcAAAAAM/RAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGHroALVp0yZp0qSJeHl5icPhkG+++cbaFhMTI6+99pr4+flJ1qxZxcvLSzp16iTnz5+3PUZERISEhoaKq6uruLu7S7du3eT69eu2Mvv27ZMaNWpIpkyZxNvbWyZNmpSoLl988YX4+PhIpkyZxM/PT77//vuHfToAAAAAYOyhA9SNGzekbNmyMnv27ETbbt68KXv27JE33nhD9uzZI19//bUcOXJEmjZtaisXGhoqBw8elHXr1snKlStl06ZN0rNnT2t7ZGSk1K9fXwoWLCi7d++WyZMny6hRo+SDDz6wymzZskXatWsn3bp1k19//VWaN28uzZs3lwMHDjzsUwIAAAAAIw5V1Ue+s8Mhy5cvl+bNm9+3zM6dO6VSpUpy6tQpKVCggPz+++9SsmRJ2blzpwQEBIiIyOrVq6Vhw4Zy9uxZ8fLykjlz5sjrr78uYWFhkiFDBhERGTp0qHzzzTdy+PBhERFp06aN3LhxQ1auXGntq0qVKlKuXDmZO3euUf0jIyPFzc1Nrl69Kq6urvLfOZ894ivx+J7u0yHV9g0AAAD8292dDe4n2edAXb16VRwOh7i7u4uIyNatW8Xd3d0KTyIiQUFB4uLiItu3b7fK1KxZ0wpPIiLBwcFy5MgRuXz5slUmKCjItq/g4GDZunXrfesSHR0tkZGRtn8AAAAAYCpZA1RUVJS89tpr0q5dOyvFhYWFSZ48eWzl0qdPLzlz5pSwsDCrjIeHh62M8+8HlXFuv5cJEyaIm5ub9c/b2/vxniAAAACAf5VkC1AxMTHy/PPPi6rKnDlzkms3D2XYsGFy9epV69+ZM2dSu0oAAAAAniDpk+NBneHp1KlTsmHDBtsYQk9PT7l48aKtfGxsrERERIinp6dVJjw83FbG+feDyji330vGjBklY8aMj/7EAAAAAPyrJXkPlDM8HT16VH788UfJlSuXbXtgYKBcuXJFdu/ebd22YcMGiY+Pl8qVK1tlNm3aJDExMVaZdevWSYkSJSRHjhxWmfXr19see926dRIYGJjUTwkAAAAAROQRAtT169dl7969snfvXhEROXHihOzdu1dOnz4tMTEx0qpVK9m1a5csWrRI4uLiJCwsTMLCwuT27dsiIuLr6yshISHSo0cP2bFjh2zevFn69+8vbdu2FS8vLxERad++vWTIkEG6desmBw8elKVLl8qMGTNk0KBBVj0GDBggq1evlqlTp8rhw4dl1KhRsmvXLunfv38SvCwAAAAAkNhDL2O+ceNGqVOnTqLbO3fuLKNGjZLChQvf837/+c9/pHbt2iJy50K6/fv3lxUrVoiLi4u0bNlSZs6cKdmyZbPK79u3T/r16yc7d+6U3Llzy4svviivvfaa7TG/+OILGTFihJw8eVKKFSsmkyZNkoYNGxo/F5YxBwAAACBivoz5Y10H6klHgAIAAAAgkoauAwUAAAAA/xQEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEPpU7sCMBM2Z2yq7duzz4hU2zcAAACQltADBQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGCFAAAAAAYIgABQAAAACGHjpAbdq0SZo0aSJeXl7icDjkm2++sW1XVRk5cqTkzZtXMmfOLEFBQXL06FFbmYiICAkNDRVXV1dxd3eXbt26yfXr121l9u3bJzVq1JBMmTKJt7e3TJo0KVFdvvjiC/Hx8ZFMmTKJn5+ffP/99w/7dAAAAADA2EMHqBs3bkjZsmVl9uzZ99w+adIkmTlzpsydO1e2b98uWbNmleDgYImKirLKhIaGysGDB2XdunWycuVK2bRpk/Ts2dPaHhkZKfXr15eCBQvK7t27ZfLkyTJq1Cj54IMPrDJbtmyRdu3aSbdu3eTXX3+V5s2bS/PmzeXAgQMP+5QAAAAAwIhDVfWR7+xwyPLly6V58+Yicqf3ycvLS1555RV59dVXRUTk6tWr4uHhIQsWLJC2bdvK77//LiVLlpSdO3dKQECAiIisXr1aGjZsKGfPnhUvLy+ZM2eOvP766xIWFiYZMmQQEZGhQ4fKN998I4cPHxYRkTZt2siNGzdk5cqVVn2qVKki5cqVk7lz596zvtHR0RIdHW39HRkZKd7e3nL16lVxdXWV/8757FFfisf2dJ8Of7s9bM7YFKpJYp59RqTavgEAAICUEBkZKW5ublY2uJ8knQN14sQJCQsLk6CgIOs2Nzc3qVy5smzdulVERLZu3Sru7u5WeBIRCQoKEhcXF9m+fbtVpmbNmlZ4EhEJDg6WI0eOyOXLl60yCffjLOPcz71MmDBB3NzcrH/e3t6P/6QBAAAA/GskaYAKCwsTEREPDw/b7R4eHta2sLAwyZMnj217+vTpJWfOnLYy93qMhPu4Xxnn9nsZNmyYXL161fp35syZh32KAAAAAP7F0qd2BVJSxowZJWPGjKldDQAAAABPqCTtgfL09BQRkfDwcNvt4eHh1jZPT0+5ePGibXtsbKxERETYytzrMRLu435lnNsBAAAAIKklaYAqXLiweHp6yvr1663bIiMjZfv27RIYGCgiIoGBgXLlyhXZvXu3VWbDhg0SHx8vlStXtsps2rRJYmJirDLr1q2TEiVKSI4cOawyCffjLOPcDwAAAAAktYcOUNevX5e9e/fK3r17ReTOwhF79+6V06dPi8PhkIEDB8rYsWPlu+++k/3790unTp3Ey8vLWqnP19dXQkJCpEePHrJjxw7ZvHmz9O/fX9q2bSteXl4iItK+fXvJkCGDdOvWTQ4ePChLly6VGTNmyKBBg6x6DBgwQFavXi1Tp06Vw4cPy6hRo2TXrl3Sv3//x39VAAAAAOAeHnoO1K5du6ROnTrW385Q07lzZ1mwYIEMGTJEbty4IT179pQrV65I9erVZfXq1ZIpUybrPosWLZL+/ftLvXr1xMXFRVq2bCkzZ860tru5ucnatWulX79+4u/vL7lz55aRI0farhVVtWpVWbx4sYwYMUKGDx8uxYoVk2+++UZKly79SC8EAAAAADzIY10H6kl391rvXAfq3rgOFAAAAP7pUuU6UAAAAADwT0aAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABD6VO7AnjyHZ7dLNX27dPv21TbNwAAAP596IECAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEPpU7sCQHLaOK9Rqu27do9VqbZvAAAAJA96oAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAEAEKAAAAAAwRoAAAAADAUJIHqLi4OHnjjTekcOHCkjlzZilSpIi89dZboqpWGVWVkSNHSt68eSVz5swSFBQkR48etT1ORESEhIaGiqurq7i7u0u3bt3k+vXrtjL79u2TGjVqSKZMmcTb21smTZqU1E8HAAAAACxJHqDefvttmTNnjsyaNUt+//13efvtt2XSpEny7rvvWmUmTZokM2fOlLlz58r27dsla9asEhwcLFFRUVaZ0NBQOXjwoKxbt05WrlwpmzZtkp49e1rbIyMjpX79+lKwYEHZvXu3TJ48WUaNGiUffPBBUj8lAAAAABARkfRJ/YBbtmyRZs2aSaNGjUREpFChQrJkyRLZsWOHiNzpfZo+fbqMGDFCmjVrJiIin3zyiXh4eMg333wjbdu2ld9//11Wr14tO3fulICAABEReffdd6Vhw4YyZcoU8fLykkWLFsnt27dl/vz5kiFDBilVqpTs3btXpk2bZgtaAAAAAJBUkrwHqmrVqrJ+/Xr5448/RETkt99+k19++UUaNGggIiInTpyQsLAwCQoKsu7j5uYmlStXlq1bt4qIyNatW8Xd3d0KTyIiQUFB4uLiItu3b7fK1KxZUzJkyGCVCQ4OliNHjsjly5fvWbfo6GiJjIy0/QMAAAAAU0neAzV06FCJjIwUHx8fSZcuncTFxcm4ceMkNDRURETCwsJERMTDw8N2Pw8PD2tbWFiY5MmTx17R9OklZ86ctjKFCxdO9BjObTly5EhUtwkTJsjo0aOT4FkCAAAA+DdK8h6oZcuWyaJFi2Tx4sWyZ88eWbhwoUyZMkUWLlyY1Lt6aMOGDZOrV69a/86cOZPaVQIAAADwBEnyHqjBgwfL0KFDpW3btiIi4ufnJ6dOnZIJEyZI586dxdPTU0REwsPDJW/evNb9wsPDpVy5ciIi4unpKRcvXrQ9bmxsrERERFj39/T0lPDwcFsZ59/OMnfLmDGjZMyY8fGfJAAAAIB/pSTvgbp586a4uNgfNl26dBIfHy8iIoULFxZPT09Zv369tT0yMlK2b98ugYGBIiISGBgoV65ckd27d1tlNmzYIPHx8VK5cmWrzKZNmyQmJsYqs27dOilRosQ9h+8BAAAAwONK8gDVpEkTGTdunKxatUpOnjwpy5cvl2nTpkmLFi1ERMThcMjAgQNl7Nix8t1338n+/fulU6dO4uXlJc2bNxcREV9fXwkJCZEePXrIjh07ZPPmzdK/f39p27ateHl5iYhI+/btJUOGDNKtWzc5ePCgLF26VGbMmCGDBg1K6qcEAAAAACKSDEP43n33XXnjjTekb9++cvHiRfHy8pJevXrJyJEjrTJDhgyRGzduSM+ePeXKlStSvXp1Wb16tWTKlMkqs2jRIunfv7/Uq1dPXFxcpGXLljJz5kxru5ubm6xdu1b69esn/v7+kjt3bhk5ciRLmAMAAABINkkeoLJnzy7Tp0+X6dOn37eMw+GQMWPGyJgxY+5bJmfOnLJ48eK/3VeZMmXk559/ftSqAgAAAMBDSfIhfAAAAADwT0WAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMESAAgAAAABDBCgAAAAAMJQsAercuXPSoUMHyZUrl2TOnFn8/Pxk165d1nZVlZEjR0revHklc+bMEhQUJEePHrU9RkREhISGhoqrq6u4u7tLt27d5Pr167Yy+/btkxo1akimTJnE29tbJk2alBxPBwAAAABEJBkC1OXLl6VatWry1FNPyQ8//CCHDh2SqVOnSo4cOawykyZNkpkzZ8rcuXNl+/btkjVrVgkODpaoqCirTGhoqBw8eFDWrVsnK1eulE2bNknPnj2t7ZGRkVK/fn0pWLCg7N69WyZPniyjRo2SDz74IKmfEgAAAACIiEj6pH7At99+W7y9veXjjz+2bitcuLD1/6oq06dPlxEjRkizZs1EROSTTz4RDw8P+eabb6Rt27by+++/y+rVq2Xnzp0SEBAgIiLvvvuuNGzYUKZMmSJeXl6yaNEiuX37tsyfP18yZMggpUqVkr1798q0adNsQQsAAAAAkkqS90B99913EhAQIK1bt5Y8efJI+fLlZd68edb2EydOSFhYmAQFBVm3ubm5SeXKlWXr1q0iIrJ161Zxd3e3wpOISFBQkLi4uMj27dutMjVr1pQMGTJYZYKDg+XIkSNy+fLle9YtOjpaIiMjbf8AAAAAwFSSB6jjx4/LnDlzpFixYrJmzRrp06ePvPTSS7Jw4UIREQkLCxMREQ8PD9v9PDw8rG1hYWGSJ08e2/b06dNLzpw5bWXu9RgJ93G3CRMmiJubm/XP29v7MZ8tAAAAgH+TJA9Q8fHxUqFCBRk/fryUL19eevbsKT169JC5c+cm9a4e2rBhw+Tq1avWvzNnzqR2lQAAAAA8QZI8QOXNm1dKlixpu83X11dOnz4tIiKenp4iIhIeHm4rEx4ebm3z9PSUixcv2rbHxsZKRESErcy9HiPhPu6WMWNGcXV1tf0DAAAAAFNJHqCqVasmR44csd32xx9/SMGCBUXkzoISnp6esn79emt7ZGSkbN++XQIDA0VEJDAwUK5cuSK7d++2ymzYsEHi4+OlcuXKVplNmzZJTEyMVWbdunVSokQJ24p/AAAAAJBUkjxAvfzyy7Jt2zYZP368/Pnnn7J48WL54IMPpF+/fiIi4nA4ZODAgTJ27Fj57rvvZP/+/dKpUyfx8vKS5s2bi8idHquQkBDp0aOH7NixQzZv3iz9+/eXtm3bipeXl4iItG/fXjJkyCDdunWTgwcPytKlS2XGjBkyaNCgpH5KAAAAACAiybCMecWKFWX58uUybNgwGTNmjBQuXFimT58uoaGhVpkhQ4bIjRs3pGfPnnLlyhWpXr26rF69WjJlymSVWbRokfTv31/q1asnLi4u0rJlS5k5c6a13c3NTdauXSv9+vUTf39/yZ07t4wcOZIlzAEAAAAkmyQPUCIijRs3lsaNG993u8PhkDFjxsiYMWPuWyZnzpyyePHiv91PmTJl5Oeff37kegIAAADAw0jyIXwAAAAA8E9FgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADCU7AFq4sSJ4nA4ZODAgdZtUVFR0q9fP8mVK5dky5ZNWrZsKeHh4bb7nT59Who1aiRZsmSRPHnyyODBgyU2NtZWZuPGjVKhQgXJmDGjFC1aVBYsWJDcTwcAAADAv1iyBqidO3fK+++/L2XKlLHd/vLLL8uKFSvkiy++kJ9++knOnz8vzz33nLU9Li5OGjVqJLdv35YtW7bIwoULZcGCBTJy5EirzIkTJ6RRo0ZSp04d2bt3rwwcOFC6d+8ua9asSc6nBAAAAOBfLNkC1PXr1yU0NFTmzZsnOXLksG6/evWqfPTRRzJt2jSpW7eu+Pv7y8cffyxbtmyRbdu2iYjI2rVr5dChQ/LZZ59JuXLlpEGDBvLWW2/J7Nmz5fbt2yIiMnfuXClcuLBMnTpVfH19pX///tKqVSt55513kuspAQAAAPiXS59cD9yvXz9p1KiRBAUFydixY63bd+/eLTExMRIUFGTd5uPjIwUKFJCtW7dKlSpVZOvWreLn5yceHh5WmeDgYOnTp48cPHhQypcvL1u3brU9hrNMwqGCd4uOjpbo6Gjr78jIyCR4psDD+/LjkFTbd6suq1Nt3wAAAE+6ZAlQn3/+uezZs0d27tyZaFtYWJhkyJBB3N3dbbd7eHhIWFiYVSZheHJud277uzKRkZFy69YtyZw5c6J9T5gwQUaPHv3IzwsAAADAv1uSD+E7c+aMDBgwQBYtWiSZMmVK6od/LMOGDZOrV69a/86cOZPaVQIAAADwBEnyALV79265ePGiVKhQQdKnTy/p06eXn376SWbOnCnp06cXDw8PuX37tly5csV2v/DwcPH09BQREU9Pz0Sr8jn/flAZV1fXe/Y+iYhkzJhRXF1dbf8AAAAAwFSSB6h69erJ/v37Ze/evda/gIAACQ0Ntf7/qaeekvXr11v3OXLkiJw+fVoCAwNFRCQwMFD2798vFy9etMqsW7dOXF1dpWTJklaZhI/hLON8DAAAAABIakk+Byp79uxSunRp221Zs2aVXLlyWbd369ZNBg0aJDlz5hRXV1d58cUXJTAwUKpUqSIiIvXr15eSJUtKx44dZdKkSRIWFiYjRoyQfv36ScaMGUVEpHfv3jJr1iwZMmSIdO3aVTZs2CDLli2TVatWJfVTAgAAAAARScZV+P7OO++8Iy4uLtKyZUuJjo6W4OBgee+996zt6dKlk5UrV0qfPn0kMDBQsmbNKp07d5YxY8ZYZQoXLiyrVq2Sl19+WWbMmCH58+eXDz/8UIKDg1PjKQEAAAD4F0iRALVx40bb35kyZZLZs2fL7Nmz73ufggULyvfff/+3j1u7dm359ddfk6KKAAAAAPBAyXYhXQAAAAD4pyFAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGEqf2hUAkLa8/2lwqu27V8c1qbZvAAAAE/RAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGOJCugCeGKOWpd5Ffkc9z0V+AQAAAQoAkkSDb1um2r5/aPZVqu0bAIB/G4bwAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGCJAAQAAAIAhAhQAAAAAGEqf2hUAACSfhsvHptq+v28xItX2DQBAcqEHCgAAAAAMEaAAAAAAwBABCgAAAAAMMQcKAJAqGn09J9X2veq5Pqm2bwDAk40eKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwxHWgAAC4S+MvF6Xavle2Ck21fQMAHowABQDAE6TplytSbd/ftWqSavsGgLSCAAUAAB5bi69+SbV9L29ZPdX2DeDfhzlQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhghQAAAAAGCIAAUAAAAAhpI8QE2YMEEqVqwo2bNnlzx58kjz5s3lyJEjtjJRUVHSr18/yZUrl2TLlk1atmwp4eHhtjKnT5+WRo0aSZYsWSRPnjwyePBgiY2NtZXZuHGjVKhQQTJmzChFixaVBQsWJPXTAQAAAABLkgeon376Sfr16yfbtm2TdevWSUxMjNSvX19u3LhhlXn55ZdlxYoV8sUXX8hPP/0k58+fl+eee87aHhcXJ40aNZLbt2/Lli1bZOHChbJgwQIZOXKkVebEiRPSqFEjqVOnjuzdu1cGDhwo3bt3lzVr1iT1UwIAAAAAERFJn9QPuHr1atvfCxYskDx58sju3bulZs2acvXqVfnoo49k8eLFUrduXRER+fjjj8XX11e2bdsmVapUkbVr18qhQ4fkxx9/FA8PDylXrpy89dZb8tprr8moUaMkQ4YMMnfuXClcuLBMnTpVRER8fX3ll19+kXfeeUeCg4OT+mkBAAAAQPLPgbp69aqIiOTMmVNERHbv3i0xMTESFBRklfHx8ZECBQrI1q1bRURk69at4ufnJx4eHlaZ4OBgiYyMlIMHD1plEj6Gs4zzMe4lOjpaIiMjbf8AAAAAwFSS90AlFB8fLwMHDpRq1apJ6dKlRUQkLCxMMmTIIO7u7rayHh4eEhYWZpVJGJ6c253b/q5MZGSk3Lp1SzJnzpyoPhMmTJDRo0cnyXMDAABPhjZf/5lq+176XNFU2zeA5JGsPVD9+vWTAwcOyOeff56cuzE2bNgwuXr1qvXvzJkzqV0lAAAAAE+QZOuB6t+/v6xcuVI2bdok+fPnt2739PSU27dvy5UrV2y9UOHh4eLp6WmV2bFjh+3xnKv0JSxz98p94eHh4urqes/eJxGRjBkzSsaMGR/7uQEAAAD4d0ryHihVlf79+8vy5ctlw4YNUrhwYdt2f39/eeqpp2T9+vXWbUeOHJHTp09LYGCgiIgEBgbK/v375eLFi1aZdevWiaurq5QsWdIqk/AxnGWcjwEAAAAASS3Je6D69esnixcvlm+//VayZ89uzVlyc3OTzJkzi5ubm3Tr1k0GDRokOXPmFFdXV3nxxRclMDBQqlSpIiIi9evXl5IlS0rHjh1l0qRJEhYWJiNGjJB+/fpZPUi9e/eWWbNmyZAhQ6Rr166yYcMGWbZsmaxatSqpnxIAAAAAiEgy9EDNmTNHrl69KrVr15a8efNa/5YuXWqVeeedd6Rx48bSsmVLqVmzpnh6esrXX39tbU+XLp2sXLlS0qVLJ4GBgdKhQwfp1KmTjBkzxipTuHBhWbVqlaxbt07Kli0rU6dOlQ8//JAlzAEAAAAkmyTvgVLVB5bJlCmTzJ49W2bPnn3fMgULFpTvv//+bx+ndu3a8uuvvz50HQEAAADgUSTrMuYAAAC4v9nLwx9cKJn0a+Hx4EIAEkn2C+kCAAAAwD8FAQoAAAAADDGEDwAAAIn8sPRSqu27QZvcqbZv4EHogQIAAAAAQwQoAAAAADBEgAIAAAAAQwQoAAAAADBEgAIAAAAAQ6zCBwAAgCfGrx9eTLV9l++eJ9X2jbSDHigAAAAAMESAAgAAAABDDOEDAAAAksCFSedSbd95h+RLtX3/2xCgAAAAgH+48Om7U23fHgP9/3b7xVlrU6gmieXpX/+h78MQPgAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIACAAAAAEMEKAAAAAAw9MQHqNmzZ0uhQoUkU6ZMUrlyZdmxY0dqVwkAAADAP9QTHaCWLl0qgwYNkjfffFP27NkjZcuWleDgYLl48WJqVw0AAADAP1D61K7A45g2bZr06NFDunTpIiIic+fOlVWrVsn8+fNl6NChicpHR0dLdHS09ffVq1dFRCQyMlJERK7dupUCtb63jP9fh/u5disqhWqSWJYH1O36rZgUqklikQ+o2400Wrebt2JTsCZ2D3rNbqXhukXfTLt1i72ZNj9rMTdT79jxoNcs5mbqHXMfXLebKVSTxJ7UusXcvJGCNbF78Gt2LYVqktgDj7mpWrfMf7v9ZqrWLcN9t12/lZr1yvS3269FpV7dsj7oXDLqegrVJLHMDzzPTb3jR6YEdXN+X1X1b+/j0AeVSKNu374tWbJkkS+//FKaN29u3d65c2e5cuWKfPvtt4nuM2rUKBk9enQK1hIAAADAk+TMmTOSP3/++25/YnugLl26JHFxceLh4WG73cPDQw4fPnzP+wwbNkwGDRpk/R0fHy8RERGSK1cucTgcj1WfyMhI8fb2ljNnzoirq+tjPVZSS6t1S6v1EqFujyqt1i2t1kuEuj2qtFq3tFovEer2qNJq3dJqvUSo26NKq3VLq/USSfq6qapcu3ZNvLy8/rbcExugHkXGjBklY8aMttvc3d2TdB+urq5p7sPllFbrllbrJULdHlVarVtarZcIdXtUabVuabVeItTtUaXVuqXVeolQt0eVVuuWVuslkrR1c3Nze2CZJ3YRidy5c0u6dOkkPDzcdnt4eLh4enqmUq0AAAAA/JM9sQEqQ4YM4u/vL+vXr7dui4+Pl/Xr10tgYGAq1gwAAADAP9UTPYRv0KBB0rlzZwkICJBKlSrJ9OnT5caNG9aqfCkpY8aM8uabbyYaIpgWpNW6pdV6iVC3R5VW65ZW6yVC3R5VWq1bWq2XCHV7VGm1bmm1XiLU7VGl1bql1XqJpF7dnthV+JxmzZolkydPlrCwMClXrpzMnDlTKleunNrVAgAAAPAP9MQHKAAAAABIKU/sHCgAAAAASGkEKAAAAAAwRIACAAAAAEMEKAAAAAAwRIBCmnDx4sXUrkKSio+PT+0q/Cs518R5nLVxWFcHAAD8HQIUUtXixYulYsWKMn/+fLly5UpqVyfJuLj876vFCXnyU1WJj48Xh8MhImL992Fdu3Yt0eMC/yZRUVGpXYV/lPj4eI4j/1D/lIbSpH4eafXzHhcXJyJJVz8CVBry+++/p3YVksW9Pqzh4eHSsGFDee211yQ0NFTatm2bJi/Q9jBiY2Ot/4+JiZGRI0fKwYMHxeFwpNgB5d968uNwOMTFxUX2798vL774okybNk1++OEH4/vHxMRI7969pWHDhtKqVSv55JNPrMdNi9LqD9STIjo6OlX2m5ZPuI4fPy7NmjWTbt26yS+//GLd/iR81tJiSFFViYuLExcXF3E4HHLmzJnUrlKaFh8fn6a/H/fi4uIiN27cSO1qPDLn9yZhg29SSPi76QwtaUG6dOkkNjZWYmJikuTxCFBpQHx8vFy5ckWaNGkiK1euTO3qPLapU6fKe++9Jzt27BCRe/8Ar1+/XiIiImTbtm3SoUMHcXNzkwMHDsi5c+dSurpJJn369CIicvjwYTl48KAcO3bMCsXJfSJ+6dIlefHFF+WDDz6QW7duJeu+0qL4+HgZOXKkVKtWTS5fvixr166Vjh07yoQJEx4YKo8fPy4VK1aUw4cPy5AhQ8TNzU0mTpwovXv3TqHaP5zY2Ng0E+wuXrwoW7duTe1qPJQffvhB6tWrJ8ePH0+xk+5Lly7JoEGDZOjQobJixQr566+/RCRtBaovv/xSMmXKJJcuXZKmTZvK+++/LyJptxHByXkC6HA45OTJkxIREZHaVRKRO69bunTpJDw8XNq0aSNNmjSRffv2pXa1bNavXy+RkZEikrqfRed76OLiImfPnpVLly6lWl3+zt1h4I8//pAXXnhBdu7cmUo1ejQJg5PD4ZDNmzfL66+/LqtXr7YC4eMcG3fs2CHDhg0TkTuhJa2IiIiQGjVqSN26dWXv3r2P/4CKVPX6669rr169dOjQodq9e3f98ssvU7tKj+zs2bNapEgR9fHx0dKlS2uOHDl069at1va4uDjr/8ePH6/u7u7aqFEjXb9+vU6ePFm7dOmiefPm1ZUrV2pUVFRqPAUjX331lfr4+OipU6dUVTU+Pl5VVb/99lvNkyePlitXTn18fLRAgQK6bNkyVVWNjY1NtvpMnDhRs2TJog0aNND169fr5cuXk21fadWff/6plStX1hUrVqjqnffkk08+0XTp0uncuXM1JibmvvedNWuW1q5dW2/cuGHdd86cOepwOPSrr76yfW5T26lTp7RixYraokULDQ8PT+3qaO3atbV69ep65MgRVf3fdyEtun37tqqqjhgxQjt06JBi+/3ss880a9asGhISoiEhIVqoUCFt2LBhiu3/Qe71+R40aJAWLlxYR4wYkWbf04T1joiI0BYtWmiOHDm0QoUKOnr06FSp093H+U8//VRdXV21RYsWumnTJj179myq1OtevvrqK3U4HNqzZ0+NjIxU1Xt/FpJaVFSUXrt2LdH+bt68qR06dFB3d3f19/fXV199Ndnr8qi+/PJLXbBggb733nvaoEED/fPPP1O7Sn/r7NmzumzZskTnVfHx8TpixAjNnj27VqxYUT08PLRt27aPvb/Jkydr1qxZtUePHnrmzBlrXynl7/a1b98+9fX11WeffVb37Nmjqo/+uSdApZLIyEgNDg5WPz8/HTlypLq7u6vD4dCxY8eqavKecCe1//73vxoSEqKzZ8+26n/06FHt0KGDFitWTG/dupXoPmfOnNFJkyZZJzLOk5sXX3xRa9asqd99913KPQFDO3bs0KpVq6rD4VA3Nzc9ffq0te3q1atasWJFHTdunB45ckQHDhyoDodDmzZtmqx1+vHHH7VEiRJp8vVKavHx8fc90L377ruaO3duVVWNiYnRuLg4PXjwoGbOnFlr1Kihv/zyy30fd+DAgVq9enVrH6qq7733njocDvX399eLFy8m8TN5dLdu3dJ169Zpzpw5tXPnznr06FFVTdkfpzVr1uj06dNVVXXjxo1asGBBnTlzpvUdTkvi4+P1+vXr2qJFC129erWqqtasWVMXLFigqvq3wTopREZGakhIiI4aNcqqz/fff69eXl76xhtvqGrKnLT+Hef+4+Pjrffw+PHjmiVLFnVxcdHXX39dDx8+bCubmu7+bdy1a5fOmDFDQ0ND9ccff9TXX3/davxITVeuXNHg4GCdNGmSdZszqKSVUDpv3jz19fVNkpNmEyNGjNDixYvrzp07bbfv2LFD58+fry1bttR169bp2LFj1cXFRefPn58i9UroXudezvfr2rVr2qxZM82VK5fWq1dPixQpog6HQxcvXqyqaeP7cbdhw4apw+HQ3r172453M2bM0L59++rQoUP1jz/+0KioKP3uu+80Xbp0umjRogc+7r2ea8Lb1q5dq9myZdOBAwfqlStXkubJPKSEzzcuLs6q3/fff6/VqlXTkJCQx3p8AlQKSnjQ3LdvnxYrVky3b9+uqqpbt27VcuXKaUBAwD3Lp0XOD2dYWJiWLl1aHQ6HfvHFF9b2Y8eOaa5cuXT8+PGqqnrjxg3t3r27vv/++xodHa1//fWXTps2TVX/F6AuXbqkZcqU0QEDBqSZXqhbt25pu3bt1MXFRXv06KFly5bVd99911ZmxYoV6u7urn/88Yd1W/fu3bV+/fq6d+9eVU26g+vJkyetx5oyZYqWKFFCjx49qvv379dBgwZZJ9X/JAlfO2dPUcLbfvjhB/Xw8NADBw5Yty1btkyDg4PVw8NDJ06cqHFxcdb3LeF933jjDQ0KCtJVq1ZZt4WGhuqYMWM0Y8aM+sknnyS6T0pJeAyIi4uz/l64cKH6+flp7969U6wuJ0+e1LCwMJ01a5Y2btzYahjp0qWLBgYG6rZt21KsLg/rmWee0ZCQEN2xY4cWLVpUv/32W9v2pHxvL1y4YB0bw8PDNVOmTPr1119b26Ojo3X69OmaPXv2NNNb7DyxV/3faxEUFKR+fn7apEkTLV++vK0hIa38Nn388cfqcDg0ICBAf/vtN+v2Hj16aPHixa3W75Ry5coVffbZZ/X48eN67do1zZMnj3bs2FE3b96sNWvW1CFDhqTKaxcVFaU3b95UVftJZVRUlC5cuFBdXFyswJkcx7n169drkSJFNE+ePFbYcFq5cqU6HA4tW7asraFr6NCh6uXllWK/Zwnfl8jISB09erTte6t6J+iVKVNGDx06pDExMbps2TJ1OBzao0ePNBee5s2bp0WKFNGnnnpKP/zwQ9u2+Ph4nTp1qjocDq1fv7712VBVHTBggHp7e1u9hA+yZcsWVbX/Pjn/+/rrr2vp0qV14cKFSfGU7ute36m3337bari6Vyh+9913tWDBgrp06dL7PsaDEKBSyL269rNly6ZhYWHWbcuWLdM6depYJ2xp2WeffaZNmzbV69eva1xcnNVy4WzldR5MJk2apNmzZ7d+yEaNGqVVq1bVjh076k8//WT1Gqj+L0S99NJLWq5cuRR+Rvd36NAh7dGjh/7xxx+6efNmzZ07tzVkyfk8d+3apQ6HQw8ePGjdb+vWrVqxYkXt1avXY9fB+eX+z3/+o/nz57eC2hdffKF16tTROnXqWAdyZ8D4p4mLi9OXXnpJvby8ErXk/v777/rcc89pnjx5dPbs2dqlSxd1OBy6ceNGfeGFF7RIkSLq5eWluXLl0hMnTqjqnRNZ1Tvvb/PmzdXNzU3btGmj2bJl00qVKum5c+e0TZs22qRJk1R5vqNGjdKPPvpIVf93/Eh4kH/llVe0bNmyun79+kTbklJkZKQ+99xz6uHhoeXLl9dSpUpply5drFbF8+fPa6FChXT48OFWIEjtE+yjR4/awsnu3bvVxcVFO3bsqA6HQ+vWrasDBgywfV8f17Vr17RLly5atGhR66Ti8OHDGhAQoLNmzbKV3bt3r5YsWVKXL1+eZPs3dfdv0b59+/S5557T/fv3W7f99ddfWqdOHZ08ebL++eefWqpUKX322WetE8rUPFlMGFJUVevVq6cFCxa0DWm9evWqurq66qhRo5JtNMe9HvfMmTNauHBh66Ts448/1s6dO2uWLFm0ffv2eunSJVW98/1IqQbC3bt3a8WKFXXjxo22253f30uXLmmbNm20ZMmSybL/559/Xh0Oh6ZPn946P7hbq1atNHfu3Hry5EnrtpiYGM2bN68OGDAgRXu3x48fr1mzZtVGjRrpJ598Yv1OqN456c6WLZut/EsvvaQtW7a0etXSQpCKjIzUatWqqaurq3bq1EmjoqISjeAICwvT+vXra61atVT1f/U+e/asenp66uuvv57oce9+bosWLVKHw6F//fWXddvJkyetIY1//fWX+vv76wsvvGAcyEx9+eWXunTp0vuOIujUqZNWrFjR+vvUqVM6YsQI/c9//qOqd47NtWvX1n79+jGELy0bN26cBgcHa//+/a0WluPHj2uGDBlsrTHnzp1TX19fdXV11V27dummTZvS7MnwCy+8YA3jUb1z8tC8eXP19/e3lZs3b556enpq586drdu2bdumDodDv/76a/X399fBgwfb7tOuXTtt3rx5mhzGOGTIEK1atWqi2//44w+tVq2aNSTReQLp7++vDodDW7ZsqZ06dXrk99P5Yzd06FBt1aqVbdutW7e0VatW+uKLL1q3RUVF6VdffZVmevEe159//qmtWrXSkiVLapYsWfSll15SVftJzLlz57RHjx5aq1YtbdCggfWD9tJLL2nmzJn1ueee0+rVq9sCrfN9On36tM6fP1/79eun33zzjbW9RYsW2q9fv5R4iomEhITYhoD+/vvvOmnSJKtHc+fOnerr62v14iaXsWPHauXKlfXQoUP64Ycfat68edXFxUX/+9//WmUmTJigfn5++uGHH+q1a9es+YEp7ccff1QfHx8tU6aMFilSROfNm2fVs1u3bupwOLRPnz66cuVKrVChgrq7u+vAgQN11apVj3Xis2rVKn366ac1ODhY16xZY5vrEhISoqGhodYwONU7DS5Zs2a1glZqWLx4sX722Wf6zjvvaOPGja06O1+H4OBg67h99OhRfeGFF9TT01M///zzFDuu/F1IcQ4zWrt2rTocDv3+++9V9X/f6enTp6urq6utZyo5JGwsCAsLUx8fH/3000+t277++mstWbKk7fO1fPly3bBhQ7LWy+n06dPqcDisz1pUVJTOmDFDmzdvbpX59ttvNXv27Lpp06Yk26/z+f7+++86c+ZM7dSp033L7tixQ11cXHTJkiWq+r/X9NNPP9WMGTOm2Pdk9uzZWrFiRf3pp5+s2xKe+H/zzTf69NNPW41WqndOxLNly6YNGjTQmzdvpplGpKtXr2qLFi0SDV93htG4uDj9/vvv1cXFRdetW6eq/6vz7NmzNVOmTPec23Xx4kVdvHix1QNXvnx53bx5s6r+b4jj6NGjrR7r4cOHa/78+W1B9HHExMToW2+9pblz59bMmTNru3btrLn2Cb9jU6ZM0fLly1u/l4cOHdI2bdrYzp9q1aqV6JztYRCgklFERITWqFFDixcvrqNHj1Y/Pz/18fHR999/X1VVO3bsqAULFrTdp1mzZvrMM89orVq1tHnz5mkmQEVERGjbtm2tVr6SJUtaSd5p+/btmilTJv34449V9c4HfdSoUepwONThcOiaNWus21u2bKnBwcE6b948dTgcOmbMGP355591yZIlWrBgQf38889T8und072+UNWqVdNBgwapqn0oRGxsrM6aNUsLFChgGwrWpUsXfe+993TKlCm24Y2mIiIitH379tY+W7dubZ04OPcfERGh9evX19mzZ1u3zZw5U6tXr25bxONJca8T2c2bN2vv3r11zZo1On/+fHVxcbF6D+4uf/XqVVX938lX3bp19ZlnntFTp07ppEmTtESJEtZn9+/mwFy4cEH9/f31nXfeSYJn9WB//PGH/vDDD6p657PXr18/DQ4Otlplt2zZokFBQTp06FDrPkWLFtWXX37Zuk9ScbYoOuf2OT9/qndaHcuUKaOTJ0+23ad9+/ZaoUIFdTgcOnLkyCSry4Mk7J0tUKCADh8+XHfs2KG9evXScuXKadeuXVX1Tqts5syZdcCAAap6571ftGiR1q9fXwsUKKAXLlx4pP3HxcXpCy+8YAvaCY/ba9as0VKlSmmPHj30xIkTev36dX3rrbe0atWqqbKowOXLl/XZZ59VDw8PDQoK0gIFCqjD4bAWYHF+J4YNG6bNmjXT69evq+qdz0L//v01JCQkxec0PCiktGjRQitVqmTV1cnHx0c7dOhgG6KUFHVQvdOAUbt2bZ0wYYLtGFS3bl3t0qWL9feKFSvUx8dHf/75Z71y5YrOnTtXPT09dfz48clykn3hwgW9ePGidfy7du2aBgYGaseOHa3nsWHDBs2WLZs1tOqnn35ST0/PJA2bCZ9b//79EzX8rVy50jZ0tGvXrurj46MRERG2cpUrV9bGjRvbyiY1Z1179eqlhQsX1jlz5uiKFSt07Nix2qJFCx03bpyeOnVKT506pfXq1bNeS6eAgADNnz+/enl5ad26dVMtPN09UqFSpUr6wgsv6Llz5/TSpUv65ptv6sCBA63vyY0bN7Rt27ZaqlQp2+Ncu3ZN/f39E71nqncWmClRooSq3ukIyJYtm77//vvWcWPKlCmaN29e63dz8uTJWqFCBVsv1eM6duyYxsXF6Q8//KBNmzbVokWL6tGjR22v+5o1a7RYsWI6Y8YM67Zx48ZpunTp9JVXXtElS5aor6+vjhs37pHrQYBKRj///LP6+/tbKf7ixYv6+uuva7Zs2TQyMlKPHz+u+fPn17Zt2+qhQ4f0yJEjGhAQoL/++muaGRvv/GE4cOCAFihQQLt06aLnzp3THDlyJPoRjY6O1kGDBiVqbRg+fLi6urpqvnz5rNs6d+6s3bp1s7aXKFFCfX199ZlnnkmViaMP4jw4NG/ePNEKXs4v7YULF3TgwIGaMWNGffPNN7Vnz57q6ur6SCv0nD9/XocNG6aRkZHatWtXrV27tn799dfq5+d3zy98mzZttHjx4tq0aVOtUKGC5smTJ9UnUT+shCchdw/ZiIuLs4YtXrt2TWvVqqX16tW75+M4J8Sq3umRqFSpkhXIDxw4oE2bNrWtgnb3j93Jkyf17NmzGhoaquXLl0+R3pTbt29r//791cvLy5oz+PXXX2uOHDlsC4R06dJFs2bNqq+//rr+8MMPWrRoUZ03b16S1CEuLk6joqK0devW1mIwqqp+fn46cOBA6++rV6/q4MGDtUKFCrY5f9euXdOdO3faWm9TgvO9HjBggAYGBtq2vffee5ovXz798ccfVVV1zJgx6unpqbt27bLKPMpCEjdu3NAePXro+++/r/Hx8Vq8eHF99tlndcOGDRoYGKitW7e2lZ83b576+flp/vz5tXjx4ponTx5duXLlQ+/3Yd1r6OfGjRu1bNmyevz4cb19+7Y1j8gZLJ1ee+01rVOnju1xktvDhBRnMFZVPXLkiGbMmNFqnHQ+zurVq9XFxcVqvHtU9/qMrF27Vvv06aNFixbVxo0b6++//66qqi+//LI2bdrU6rn49ddftWnTppo7d24tXbq0FihQwBril5RiYmK0W7du6u7urmXKlNEWLVpYx65hw4ZpqVKlrHmK586d09q1a2vJkiW1Z8+eWr9+fS1TpkySLJgTHx+f6PNy4MABzZIliz7//PM6fPhw9fLy0rJly9p6Zc+dO6eurq46ceJE63FU7zTMOhyOZFmh+O7Gt40bN2qRIkX05Zdf1lu3bumxY8d069atWqtWLW3VqpVGR0fr/PnztXTp0tZxOjw8XAMCAvTUqVOJFsdIbXv37lV3d3etUaOG5smTR93d3W0jLFTvfD7d3Nz0vffeU9X/vSbff/+9PvXUU1Zjo/M3eeXKlerl5WUtovX8889rmTJl9NixY9ZjPvPMM/rUU09py5YtrQbypBjaeK/H2Lp1q2bNmlUrVaqU6LcwJCREa9SoYQ1f3bRpk+bMmVNffvll9ff3127duj3WsY0AlYRu376tX375pTVkZPr06VqgQAFbmdOnT2upUqWs1spt27Zp5cqVtUKFCurp6WlrXVZN3dX4Dh06pM2aNdPo6GiNiorS+fPnq5ubmzWmuVWrVjp16lTbcI5jx45phgwZbD/GUVFR+vrrr6uIWEOSBg4caGvdiIqKSvahFg9r5cqV2q5dO9ttbdu2TTSW/e73aNasWdq3b1/t1q2bbZjTw7RKDRkyRFu0aKGqd1oHQ0JCtFSpUpohQwb19vbWxo0b66JFi6yWpPPnz+vixYv11VdftQ2tfBINGzZMg4KCtGfPnrpt27ZEr298fLyuX79e06VLZy0GEBcXp0uXLtVChQppiRIltFChQurv768ZMmTQwYMH2177+fPna8mSJa2gfvdSuiNGjNCcOXNqjRo1kn152gMHDtgaG5YtW6Y5cuSwWtd9fX21QYMGVm/bihUrtFSpUtq8eXMtUaKEdu/ePUmOEQlXmfLx8bFOBlVV33rrLc2ePbttNc2ZM2eqw+Gwhq06h4CkpCVLlqirq6u+/fbbqqrap08fbdOmja3MsWPHtFGjRvrCCy9Yt2XLlk2ff/75x+6VGDVqlFauXFl79eqlK1eu1F69eqmbm5s2bdrUmvMZFxdnnUiHh4frmjVrEk2iTwkJj0OjR4/Wp59+2ra9R48e2q5dO2u4i+r/hiU+6jHsYf1dSClSpMjfhhTVO8eNnDlzJlo4okmTJhoQEGB7Ho8iOjpap02bpp999pnu3r3buj0sLExr1qypTZo00T/++ENnzpyplSpVst03MjJSN23aZPXyOSXVfJmYmBjt27evBgYG6tq1a/Xzzz/XYsWKaYMGDfTIkSP666+/Wj05TrVr19YhQ4bo22+/rZ06dbJ+0x5HwmPR+fPn9dNPP7Ued9myZTplyhTNnz+/NmzY8J6LQ0yZMkWzZMmS6LIInTt31hIlSiRZj+3dr7tzPp3qndEOdy8S9fXXX2uFChV09uzZGhcXp++//74+9dRT2qBBA/Xw8ND27dun2iqkCb+TN2/e1BYtWujy5cut0UJhYWE6b948zZcvn23YqPM1iI2N1SFDhqjD4bDmtDu3V6tWTXPkyGFr0P/uu++0fPnyViPUn3/+qZkzZ9aXX35Zjx8/rmFhYdqhQwddvXq1fvrpp4nm3j2KhCvoOTk/a2FhYerq6qpVqlTRQoUK6bvvvmsd27dt26bly5fXChUq6MqVK/XVV1/V7t27661bt5JkThYBKonMmTNHM2TIoLVr17ZONObPn6/ly5e3Vv5SvfNhf+211zQkJMQaanTjxg3dv39/qi31eLeffvpJlyxZovv379cMGTJYJ5F//vmndujQQR0Oh06bNk2HDx+uOXLk0EqVKunUqVOtcl999dU9w1BoaKg+/fTT2r9/fy1TpozOmTNHVTXJxsY+qnuFINU7450dDoft5HDx4sWaK1cuXbt2baLyzi/t3ZM1TU9w169fb12XoEaNGraJ52PHjtVcuXLpG2+8oYcPH9aBAwequ7u7litXTmfMmGG1BqX2uOvHcfHiRa1Tp46WK1dO33rrLa1evbp6eXnp1KlTrTLO1/XWrVvapUsXLVKkiKreOdEqVKiQzpo1S1evXq0tW7ZUFxcXHT9+vPW+OH/gzp49q926ddOKFStaB9GEP3579+5NkV6UkSNHatasWROtkNSgQQNt0KCBqt75THh4eGjTpk11+/bt2r17dx0xYoRGRUUl2fHi448/1j59+ujt27d11apVWqVKFVX932dp3759WrJkSds8xh9//FFbtmyp8+bN06FDhybJEClTzp59h8Ohfn5+1jDV3r17a5UqVRKdmDVr1kx79OhhfQ83btz4SHMqFi9enOjEyjmfc/Xq1frHH39oyZIlbSd527dv188//zzR0LLkcq+l/l955RX18fHRDz74QFVVP//8c82TJ49teO+ePXs0c+bM2qJFC42NjdVbt27pF198oS+//HKK1V310UKK8/levnxZCxUqZJ2wJVxgJnPmzI/UQOd8jKVLl6qrq6uWK1dO/fz8NEOGDPr+++9boWzv3r3as2dPLVy4sE6cOFGzZctm9f7cKyQl9fL5Fy9e1IIFC1rXHVRV/eWXX7ROnTrWEN958+apq6ur1qlTR998800tVqxYopPbpGqwHTBggGbLlk179eple903b96sHh4eVo/w3b9Xt27d0uLFi1sNYwlHd2TOnNmaa/M47n6OS5Ys0fz581t/f/rpp/raa6/prVu3rP3fuHFD69Spo3369LHu/9tvv+myZctsvdlpwZtvvqktWrTQ9u3bW7c1atTINqz0bmfOnLH13jrPyQICAjRLlixaq1Yta8GbS5cuacaMGW1TON5//319+umntUyZMlqpUiUtVaqUbSjm312C5G53fyYSvl9HjhyxTYVwPqZzasXChQs1d+7cOnjwYGsY9ffff68hISFapEgR9fb2ts1fe1wEqMe0du1a9fb21vz582uuXLl0wIABVjf45s2btWrVqjp8+HDbfVq3bm31xNzrw5JaJ8E3btzQ0NBQdXNz01KlSmmVKlXUzc3NumaK6p3Wh2zZslmrgx04cECnTp2qnp6eWrlyZds45Xs9jylTpmi1atXU4XAk6kpODQm/1BcvXtQjR45YJ9W3bt3S0NBQ9fX1td2nUqVKGhgYqAsXLtRjx47phg0btGHDhtqvXz+r5cz5A2l60IiIiFBvb28dOnSonjt3TitWrKj79u2zth87dkxDQkK0YcOG1mu8a9cu7du3rwYHB6fapP2k5AxBCVdievHFF7VixYrW5OKEB9ODBw+qu7u7Tp48WUePHq3PPPOM7YSgb9++GhAQoF9++WWiz+LKlSs1ICBA33zzTf3tt9+0cePGtut6JZfr169ru3btrFWRunfvriVLlrQaE1RVFyxYoN7e3lYDywcffKCBgYGaL18+zZcvn/78889JUpcVK1Zoz549reuErFu3Tnv37q0tW7a0jVePiYnR1atXa6ZMmbRNmzY6a9YszZMnjzWEJaXExMTooEGDNFOmTNq1a1dt1qyZNcdF9U7vvpubm44fP942BykoKEhfeeWVx9p3bGysNZ9z5syZVotsbGysNmvWTNu0aaNHjx7V9OnT65YtW/TChQu6ePFizZcvnw4ZMuSe18JLTgnfv5s3b+r48eO1ePHiunjxYj1z5ozWrFlTe/Tooar/O7kpXbq0ent769NPP62tW7dO8WF7SRFS7m6Mc97+oICfcPvdx4rIyEitVKmS9Xm/deuWjhw5UkuWLJloxdz27dtrwYIFNUuWLEm6IMODOBeUuTtgDB06VKtUqaKnT5+25oy0bt1aAwICrEDtlBS9YVevXtXnnntOAwICrEaohI87d+7cRKNyVNXWgHz3vG/n/ZMyyJ86dUq7d++uQ4YM0VmzZmmzZs2s4cjffPONurq6Jlqhs0qVKomG5qaGu9+n5cuXa2hoqO22NWvWaKFChaw5bq1atdKaNWuq6p3j6JUrV/Ttt9/WsWPH2lbfVL3TQ+08nqneOZYMGDBAfX19dfny5RoXF6dBQUGJVunbtGmTjh49WocPH277Hj7M+Wx0dLStMTPhex8aGqq5cuXSgQMH2uarOq+p6vx+zpw5UytUqKBNmjSxHQcPHTpkXA9TBKhHdObMGW3Tpo06HA597bXXVPVOy17BggVtFyHr37+/5s+fX9966y09dOiQ/vTTT1q0aFFr2Ela8p///EdLly6tx44d0wsXLuj06dPV4XDoW2+9ZZX566+/tG/fvlqsWDHbF8O5NPT9OMtGRUXp2rVrrQCWVgwYMECzZs2qvr6+toP//v37NWvWrLZhcQcPHtR27dpp+vTptWLFipo7d27t0KGDNm/eXIsVK/bIdZg5c6Y2a9ZMe/furVmyZNHevXtb15tQVf3www81MDBQp0yZ8nhPNhXd60fa+dn45JNPtESJEraD459//qmhoaFarVo16wc04YU/J06cqE899ZS6u7uriOiPP/5oHYAjIiK0evXq2rlzZ+sxnSeFN27c0L59+1rL6wYHByfrymI3btzQ9evXa1RUlObNm9dqzTtz5oyOHTtW06dPb61sNHv2bA0ICLD9CN2+fTvJWjqPHj2qTZs2VYfDocHBwRobG6vPPvusVqtWTb29vbVEiRJavXp1/fHHH20n/qtWrdJhw4bps88+q5999lmS1OVh7Nq1S4sVK2YNgbt165auWrVK06dPb53Ijho1Sn19fTUkJES//vpr7dy5s+bNmzfJVvF64403tEKFCrYVLzt37qwvvPCCRkdHWxfZLFmypHp5eVmtusnp7nlOS5Ys0aJFi9oaE8LCwnTAgAFatWpVjY+P15kzZ2rp0qWtid4nTpzQSpUq6fnz55NtHkdKhZSHCQIXLlzQJk2aaOvWra3Fj+62fv169fT0tPXYxcfHa8OGDbV9+/Z6/vx56/a//vpLZ8yYoU899VSSzU2825gxY3TkyJG6YMEC67lGRUWpu7u7Tps2zfba7tixQ5966inb5VLuDvMPc4K7efNm7du3r65fv94KPAmD9qlTp7R06dLW/NvffvvNGlWhemd0S4YMGXTkyJHWeYCz8blx48bW8Mvbt28nSUPyvR5j06ZN6unpqa1atdJmzZpppkyZ1NPT09ZzXbp0aeu6cap3zgP8/f1T5bIDTnePlHE2pH7xxRfWJTsSbnvllVe0Ro0aqnrnuoF58uTRChUqaPfu3TVfvnxauHBhrVKlilarVk1PnTqlP/74oxYoUEBLlSqlixcv1tOnT9sWIhk3bpx6e3vrzJkztWrVqtZc7Pv1pj5sA8y4ceO0WLFiGhISon379rWC9JkzZzQwMFDr1q1rNSo731fn579Zs2b63HPPqeqdEHbo0CHNnTu3Nm7cOFkblwlQj2jEiBH6zDPPqKenp22IXt26dbVp06ZW68Uff/yhZcuW1WzZsmnTpk3Vx8cn1ZZFvpdPPvnEmm/x7rvvat68ea2TzejoaB04cKAWL17cdp/Nmzdby//eLS0uPf4g06ZNUz8/P127dq1u2rRJ69evrwEBAdY1T5xDFZ09Aqp3vrh79uzRH3/80epx/OWXX7RkyZK265E8jKioKA0MDFR3d3dt27at1q1bVwsWLKjNmzfXX3/9VWNiYrRZs2b67LPPWi0rT+qQvW+//VZ/+eUXW1iaP3++FipUKNFQm6VLl2rFihV1zpw5unbtWu3fv7++8847+tVXX2nDhg3V4XBonTp1NHv27NbnzxmiPvjgAy1evLjtx+X69ev6zjvvaLp06bR27dq2nr7k8MEHH2jWrFnVx8dHS5curaVKlUoUgvv166clS5bUSZMm6Ycffmi1Fqom3XscHx+vr7zyirq4uKivr691Xaddu3bpf//7X3U4HOrp6alr167VLl266DPPPKPlypXT2bNnP/IKdY9rz549Vq/uunXr1OFwJKpL3759raGcqnc+W0FBQVqlShWtV6+edf+kEBUVpe+//75mzZpV33zzTVW9M5/T2TIdGxurv/32m20lzuRy9+ci4bj/9u3b24ZKqd6Zk+vn56dXr17VsLAwnTlzpqZPn14bNGigTz/9dJLNp7tbWg4pK1as0KZNm2rnzp3V4XDopEmTrM+X8xiyd+9edXFxsSbJO1/nr7/+WnPlymWFk7tXnStevHiSLMrg9PPPP6uXl5eWK1dOn3/+eXVxcdH27dtbgXfo0KHq4eFhm8fmnAuVsFff6WHf6z///FNr166tpUuXVi8vL2sRqIR2796t5cqV00aNGmnDhg01U6ZM+t1339nmWE6bNk1z5syp5cqV0xIlSuicOXN0/fr1WqZMGVtj7aPauHHjPRubnHUYO3as7dpHU6ZM0XTp0tkaO3777Tf18fGx5jTmzJlT27Ztm+TXMjJ1d2N1u3btdNSoUXrlyhWNjo7Wdu3aqZ+fn+0+8+fP10qVKunJkyf19u3b+t5772mVKlW0WbNmViP/t99+qxUrVtTffvtNGzZsqP3797fuf6+GiBEjRmjr1q3V4XD87fURH/Y3a968eerj46PLli3TadOmaZEiRbR+/fp68OBB3b17t3p7e1tDo3fs2GF9F511HDt2rDZq1Ehv3rxp7Xv37t22uW3JgQD1ENasWWOtYuPk5+en7du3t4b//Pzzz5ovXz599913bdejqFKlis6aNcvWqpyaF1zbunWrFQCdEwunTZumxYsXtx18wsLCNFu2bPrKK69oWFiY9aMyf/78NLfizIPc6/WOiorS8uXL21YdO3HihHbq1EmDgoL0xo0bGhERoSVKlNA6dero9OnT7zscaPbs2RoSEvJYc7o2bNig7u7uVo/Xpk2btFatWpopUyZt3bq1Ll26NEkm+6aWlStXauHChdXX11cLFSqkfn5+tonVbm5uOmbMGNt9Ll68qLVr19ZChQppnjx5rGGV6dOn16JFi+rBgwf1yJEjmi9fPmtYQcL3wNPT07YU+cGDB7Vy5copcsHqU6dOably5fTTTz/V8PBwHTx4sGbKlEl79uxpq2d0dLSOGzfOWlJ69OjRSV4X51j/n3/+WePi4vTixYtas2ZNrV+/voaHh+tbb72lWbNmteYyXrhwQfv27atubm46c+bMJK/P37lx44ZevnxZS5QoYbUCr1u3Tn18fKwVzJzf559//lmffvpp25yZmJiYJD15vdv8+fM1b9681nzOu1ewSm53L+vdqlWrRO9R/fr1tWrVqtaJ4erVqzVbtmy2IVK//vqrLlmyJFkX8HlSQsqsWbO0SJEi2rZtW9vtkZGRGhAQkOh6MTt27NDMmTPrr7/+muix/vrrL3VxcdFXX301SeqmeueyJwkXQ1m7dq3WqVPHqm9kZKTmz59ffXx8dPTo0Tp//nz18PDQLl26JMmcq5iYGOuz8/HHH2uJEiW0Xbt2ttXXVO80eowbN06LFi1q+07++eefVi9/eHi4Hjp0yDr+Xb58WQMCAmxzuB7WrVu3tGnTpurq6qru7u76zjvvWL+VCcNiUFCQPv/889ZnLzw8XIcPH2676KqzvsuWLdNJkyYl2bDph3V3EHnzzTc1c+bM2rp1a/3ll1+sXsA9e/Zo1qxZreOQ6p3Pp6urq166dEn379+vFStW1BIlSmiOHDl01KhRGhMTo4sXL9ZKlSrpxo0b1c/PTwcPHqxXr17VF154QRcuXGi9P87X7/r167p+/XrNkSOHlipVKtFiH48qJCTEtvDYkSNHtFKlStqxY0f9+OOPtUCBAtqjRw8NCAjQokWLJno/Ro0aZc2JTMlGfAKUgbCwML1165a6urpq//79bZPjVqxYoW5ubvr5559bB6kuXbpomTJldODAgbp8+XK9efOmBgUFabt27ayWtNRaseXChQtWC8Lzzz9v2xYREaFZs2bVsWPHWi0tx48f1zx58mhAQID6+PgkyepVqSkiIsK2StOFCxe0Zs2atjkoqnd65sqWLWtdl+fAgQPasmVLLVu2rLW4Q8LVapJKfHy8tmjRQjt06GD9MMXExOimTZsSXRDvSRIbG6sfffSR+vj46OTJk/Xy5cv6xx9/aJ06dbRdu3bWSdDEiRM1R44ceuDAAdsE3qJFi+rTTz9ta1EqU6aMdUJx+fJlfeuttzRz5syJFtSoVauWdu/ePcWe6/nz5/WVV17RqKgoXbVqlebMmdNqbLh8+bKOHDlS8+TJY5VP+Dydk3GTYxGLQYMGqb+/v169etX6zK5fv16rV6+ukyZNUlXVnDlz6vDhw22rLt19XZbkdOPGDX3hhRfU399fZ8+ere7u7lbdTp8+rfXr19fu3bvbVlT79NNP1dvbO9Hqa8kttedznj9/XocPH65XrlzRmjVrauvWrW29bSdPntQXX3xRs2TJohs3btS5c+dq3bp19fbt26k2UiAthJSEE9oT/n9cXJyWKlVKHQ6H9urVyzpJi46O1s8++8xaStv5fXj11Ve1fv369w0nS5cufazr8F26dEk/+OADvXjxol65ckXLly+fqHHpvffes1YYU1Wrnr169dLWrVsn2Yqsd//WxcbG6rhx49ThcNiGVjnNnDlTa9WqZX3OoqKitHfv3onmXTkf8+TJkzpu3LhHHr3htG3bNj19+rROnjxZCxcurB07drTOV5x1f+ONNzRfvny2oYxffvmltZT/nj17Un1F4NjY2ETnFVu2bNGSJUtaF4xO6Pbt2zp8+HDNlSuXFao+//xzDQwM1MuXL2t0dLQ1amXcuHFapkwZ7dq1q+7du1cjIiI0Ojpau3btqs2bN1c3NzetUKHCPXvunXVasmSJli1b1naNpUd17do1bdiwoXWcd/roo4+0VKlSOnz4cN27d6/26dNH/f39bUMtnfPWlixZogUKFEjWa4XdCwHqb0RERGibNm20UqVKGh0drTNmzFAfHx/bdVlU76xwUrt2bWuJ1fDwcG3Tpo3my5fPmvy+ePFi9fPzs/V0pLTJkyerw+HQ2rVra7169WwTD50tDePHj9ciRYrYWucrVKigW7Zs0Y0bNz5RQ/Tu1SrSq1cvDQgI0AkTJli3VapUSXv27GmbcHj+/HnNli2b7UQ24RKfpvt7FEeOHFE/Pz9riNA/wc2bN3XAgAE6efJkvXXrlnXS8fHHH2u+fPlsP8y+vr7atGlT2xLiRYoU0QYNGmh8fLx1X+cy0s6/jx8/rtWqVdMqVapYQ1ZOnTqlvr6+KXLNHachQ4Zoy5YtVfXOipSurq5WL4rqndD+zDPPaI8ePVK0F7pv377q7++vqvZWuueff95a1GbGjBnqcDhs9U0pUVFR2rRpU61bt67OmDHDuoZIwpOgDz74QAMCArRHjx569uxZvXDhgoaGhmrLli1TbKGGtDKfc8iQIdq8eXNVvTPxvXz58rbjmuqdQOpcqKRixYrW+5zcnoSQEhUVZTvuxMXFae/evbVq1apar149LVeunO17MHjwYM2VK5eWL1/eWmApOa5NpHrn0gHOOYqqdwJmoUKFrBVJnfU+ceKElipVyrrOXUxMjFaqVEnbtm1ra6R91N/thMenI0eO2P4eP368urq6aoMGDdTT09O2KtvYsWO1evXqOmTIEP3000/Vx8dHy5Qpk2jUSlIOT77blClT1OFwaKdOnWwLQhw+fFhz5sxpO2Hft2+fOhwObd68uRYqVMgaaprSQ+Tvnuf0888/W/Pl586dqwULFtSNGzfqL7/8om3btrUN1wwPD1c/Pz8tU6aMDhs2TAsXLpxoATPVO7/FgwcPVofDoZ07d7bek9jYWP3++++1RIkStgaqTZs2We9twrq98MILGhgYmCS9c3Xr1rU1qsydO1dz586tHh4eWrduXT127Jj26dPHthJsWFiYtm7dWvfv36/nz59PlVWsCVD38frrr2vmzJkTXQQsICBAQ0NDbWOKjxw5ojlz5tR33nnH6rm5dOlSooNWq1atUu3H9vLlyzp37lwrELz//vtavnx561o4CQ+2vXr10kKFCmnz5s3V09NT27VrZxv2kdZDVFxcnK2OCeeoxcTE6CeffKKlSpWy3otPPvlEM2TIYIVd1TsT1gsUKHDPZVNT4vkPGDDgnq11T5K7w8G2bdsS9V5++eWX6u/vr5GRkVb5Xbt2qY+Pj5YrV06nTp2qAwYMUHd3d6vlzVmuffv21kpiTmfPntWiRYtqoUKFtFWrVtaV4RNOok4Of7cEfb58+XTQoEHW5+avv/7S0qVLq7u7uzZp0kSfe+65FFkBcPfu3eri4mIN2XWeHAwePNg2z/HupbqT25o1a/Szzz7T06dP23rrrl69qsHBwVqhQgXrhDo6OlqXLFmiefLk0ZIlS2ru3Lnv21r6T/R3n7OuXbtqvXr1rJ7qhN+/rl27qsPhsA3xSQlpJaTca+nqoKAgvXjxou0kuX79+jp8+HA9deqUtm7dWgsVKmS7bteGDRt0+vTpOnHixGS5/MaSJUs0R44cWqxYMfXx8dHevXvruXPnVPXOkMWiRYtaf6veGbbm5uZm+63YuHGjPvXUU481Dy/h6+V8/8qWLWsL6P/5z3/Uzc1NL1++rM8//7xWrlzZCiVnz57VoUOHavXq1bVChQr3vPj74zh48OB9e6uc9f3tt9/U4XBooUKFNCQkxDYf8N1337Xm0Dmv69S2bVu9ePFiiva4J5SwkeDixYvW/F7n8POff/5ZW7RooXXr1lUXFxd96aWXrN9T5/t14sQJHTlypDZs2NB2bLjb6NGj1eFw6HPPPacFChSwenLmzJlju+7gjz/+qFWqVNFRo0ZZ+0g4dLpJkyaJVit8FMuXL7fOwcqWLauFCxfWr776SteuXau1atXShQsX6quvvqpVq1bVuXPn6ty5c7VQoUJarVq1e87vSykEqLvs3LlTixQpoiVKlNAXX3xRfX19tXbt2tbB6KuvvtJ8+fLZVsBRvXMhwjx58lgfRKfY2Fjri5Gcq3zdy++//67ffvutnj17NlEL3pkzZ7Rjx45au3Zta5yws8y1a9d09+7dOmXKlMe+gntKStg7oXrn+a9du9a6TovT1atXdcSIEerj42P9eFasWFGzZs1qDTMoXLiwPvvss7aFI1JSas6Pe1x3t6LdHV4Sbn/11Vetax6p/u9579mzRwcOHKgNGjTQmjVr2kKwU7Vq1awl9hNeaO/o0aP6+eef68svv2xbgj+5PGgJ+oULF2qGDBms4aCqqo0bN9YpU6bo0qVL7/nckkNsbKx26NBBixQpogcPHtS4uDiNjIzUevXqpUrP+B9//KEhISHqcDj0ww8/1F9//VU9PDxsr9O5c+c0S5YsOn/+fNvx8+TJk7plyxbbhSH/6R70Odu9e7dWqlRJX331VatBzHmCFR4e/sCVUh/XkxJSVO8s2pJwnmHC4V0JL4LbpUsX9fPzu++816S6ntORI0e0bt266nA4rB6HBQsWWBdvVb3zu5wzZ07t0aOHNRf7ww8/1DJlyiRqQGjRooXmy5fvsZf+HjdunDZq1EhfffVV7dWrl77xxhvWa/X999+rr6+vnjx5Ui9cuKCTJk3S9OnT64wZM6ypCn/99Zfte/s4jY/O6xOVKlVKM2bMqJUqVbJdE+ju3qJ9+/ZpjRo19M0339TevXurm5ubrlmzxvpMvfTSS1q5cmX18fHR/Pnzp5lznTfeeEOfeuopLVy48D3fvx49etiu6RQTE6OLFi2670I/Cc8lnP+/cuVKzZ8/vx48eFCfffZZrVy5sn7xxRd6/PhxLVKkiPr6+mq9evU0S5YsiZYrTw7Xr1+3Pv/jx4+3zfMODAzUt99+Ww8fPqydOnXSKlWqaJkyZVJkhdMHIUD9P+dJXs+ePfXZZ5+1fngOHDigoaGhWqpUKevD17JlS61Tp45+9913umfPHr1586ZGR0enyMU3Tdy8eVM7duyo2bJlUx8fHy1SpMg9V/774osvtFq1atYy7JcuXbpvl3Va73VKWL/r16/ryy+/bF3wt2HDhlq2bFlb+Z9++kn9/f2tCenO1qoWLVpoz549n+ilwtOK48ePa8uWLbVp06Z6+PDhRNtjYmK0QoUKf9vTlnBMc1xcnPX5PHbsmHp4eNgWPEnNCzLfvQR9r169bEvQd+jQQYsWLaodO3bUhg0baokSJZJ9haB7uXXrlvr7+2vBggW1YcOG+swzz6ifn581/DglxMbGardu3dTFxUWrV6+uZcqU0ZkzZ+p///tfLVKkiI4dO9bWUxkSEqJPP/20jhgxQmfPnp1q80fTggdd6mDSpElaqlQpbdOmjT7//POpOm8ytUNKwt+EK1euaMOGDa15peXKlbOG9Sb8zZs4caIV+lTvjNyYP3+++vr6JlqsIimGd0VFRek333yjXbt21Vq1amnp0qWtnvbY2Fht3ry5NmnSxJoD9s0332hgYKDmyJFDK1eurJkzZ77nAi8nT55MNK/XlLOBq1evXlq0aFGdPn26+vj4aPr06W3XQTp16pRmzJjRdn2dKVOmaIkSJazfT+drlBTXt3Tef+XKlbphwwbt06ePZs6cWT/66KNE85xU78yZfPrpp61RJM7pGM6h8fHx8Xr58uUUvV5XQvHx8bbXZMOGDZouXTotVaqUNmnSRGvWrGk1eiRcxKFp06Y6YcIEjYiI0NjYWB0/frxWqFAh0QVi/64R9vPPP9fSpUtrZGSkXrhwQV999VXNli2bfvvtt7pq1Sr96quvdMKECbbPfHI36q5atUpdXFys98P52vTt21fbtWtnlUu4Imdq+9cHqGvXrmnLli01ICBADxw4oM8++6w1kdVpw4YNtqWHjxw5os8995wWL15cHQ5HmpvcP3HiRC1btqzu379fjx07pu+//75mzJhRp02bpqr2iwtOnjxZc+TIofXq1dPAwEA9cOCA7bGetGWyx44dq5kyZVKHw6HZsmXTFStW6Pbt2zVnzpy2H5qLFy8mms/Wtm1brVSpkm3uTVJfMf6fzvl5WbBggWbPnl07duyo33777T27+Z3D7Zytp+fPn9cJEybcs6X87mvdLFy40LZ09ahRo7R3796PPQn5Ud1vCfpmzZpZvQTr1q3TQYMG6ciRI1Oljk7nzp3TFStW6LBhw5LtWjX3s2DBAs2aNavmzZtXw8LCNC4uTocNG6Y+Pj76119/6ZAhQzQwMNA23KZRo0bapUsXbd++vXbq1Mm2VO2/zYMudaB6Z5RE69attW/fvslen7QYUhLW6caNG/rbb7/puXPntHjx4tqiRQs9f/68urm52Y7zzvt8/vnn6unp+Vj7fxjOOaDOnvIaNWpoaGioVbcffvhBK1SoYFs8IiIiQr/99ludN29esk2av3z5svr5+Vn1On78uIaGhmqOHDmsBWbCwsK0QoUK1jQAp4Sva1K6129xp06dNF26dDp48GDb7c73s2zZslbvekREhM6ZM0cdDoeOGDEiSS/M+zic4e+7776z5l798ssvWrNmTVvDt/O8bfDgwVq4cGGtVq2alixZUgsWLGgbYWPi5MmT+tRTT9muqzR69GjNmzevfvjhh7aySRF+TfXv3199fHx0x44dGhcXp1FRUVq3bl1rjl9a868OUDNnztSsWbNqgwYNrKF3QUFB2r17d9vQrWvXrmnjxo11+PDhtpaAXbt2pdp1Ae62detWjYuL01u3bqmPj4+OGDHCtn3KlCnq7u5uPS/n87h586auXr1aBw8enOzXw0lOUVFR2rVrV33mmWd0yZIl+sMPP2jdunW1evXqunTpUp08ebK6ublZE83j4uLU09PTNsTrypUrmiVLFp0wYUKiq6Hj3hL2Cjk5h4VNnDjxb++7atUqDQgI0EuXLumYMWOsMdkmJwX9+vXTIUOG6Nq1a63lzVN7CMb9lqDPkiWL1qtXL9nnYaV1N2/e1D59+lgXRXSeLG/cuFFr1KihL774ot68eVPr1q2rgYGBVuNH0aJF9YcffvjXhqa7/d3nLCgoSM+dO5fsIwaehJAyfvx4zZkzp3UJjh9++MG6dpLzOjZDhgyxNbrs3LlT8+fPb1t+2ympGtPuHhbetGlTbdSokYaHh+uKFSu0ePHitt6j3r17a/ny5bVTp073HLYUExOT5K/hrl27NFu2bLp27Vrrtr1792qdOnWsnsKoqCgtVqyYtfT43T0USdVjcfec5oQ9N99++63VYDpo0CBbIIiMjNSgoCDbJSyc97nXiIiUcPf3ctasWdqiRQvrmpMJy7355ptavnx5q2fJ2fN+69YtXb9+vU6ePDnREHXTz8GxY8c0ICDAuuCx092rXabGMbdHjx7q5+enDRs21KJFi6q/v3+yDz9+VP/KALVs2TLreivPPPOMbdLge++9l2hFGVXVUqVK3Xe51NTspTh27Jg2atRIHQ6HNZypRo0aOmTIEFX93wpIly5dUi8vL2vZyft9MZ7UuTcXL17U4sWLW6sUOW9r0aKFtm7dWnfs2KFly5bV1q1b64kTJ3T58uVauXJl6yTO+R6++eab6nA4kmRi5D/Z3fOcEi6CsHv3bs2ZM6fVKna/z1qfPn3Uzc1Nvb29tVChQrpu3Tqjfd+6dUuLFi2qDodDM2bM+MCgllLutwT9L7/8kmrDRNKidevWadWqVa1W45iYGJ0yZYp1DbpLly7poEGDNCAgQAsUKPDEL6aS1NLS5ywthpSIiAgNDg7WYsWK6RdffGH1dF67dk179+6tDodDR40apXPmzFFvb28tVqyYvv766/rbb7/pjh07tEOHDsm2oteLL76o/fr1s634unHjRi1WrJhOnjxZVe+sihkSEmItpnLs2DGrZd45F9t5TE3OE9wCBQrYhlXevHlT27Ztqw6HQxctWqTbtm3T2rVrJ+uiMwnPR44ePapDhgyxrTy3aNEiDQoK0ilTpmidOnW0XLlyGh4ebr0ujRs3toZ/pcVzm99++00nTpyo6dOn15UrV9rC4d69e7V58+bWypmxsbH3XeDiYb83t2/fVg8PD12+fLn12AmlZmNVdHS07tu3Tz/++OMUmcP8OP51AWrt2rXq5eWl77zzjq5cuVJr165thQ2nKlWqaEhIiC5btkxv3ryp3333nZYqVco2rCS13b59W7t06aIOh0MdDofWr19fr1+/rtHR0dqlS5dE807++usvLV++/N/O7UmLBxhTv/76q+bIkcNqrXE+l48++kj9/Pz0p59+0m3btqm3t7eWLl1aM2fObHstEh4wUnqlqidZWFiYPv/881q2bFnrh23z5s3q5uaW6GQu4WscHR2t9evX17x589paW+8OZvcTFBSkffr0SbGlq039E5egT2pRUVH62muvqb+/v27ZskVV78w1bd68ufr6+mrHjh316tWrtpNM2KX25ywth5RffvlFK1asaC3O4rw+WHx8vO7evVvd3d2tsHLu3Dn95JNP1M/PT0uVKpXsw7o2btyoxYsXT7RCXs+ePbVy5cp6+PBh3b9/v5YsWVLHjBljjYRI6evbqN65pEHmzJn1zz//tI7dAwcO1Lx581oXmk+4ImByiYuL0/79+2uWLFm0VatWumfPHmu+68GDBzVdunR69uxZPXHihFapUkUrV65sBYOePXtq69atU3wBr4R1T3hedejQIa1Zs2aiBlrn/CznfZy++OILLVasmAYGBqqfn59t0QzVRw868fHxWq1atRS/QPo/zb8uQN28edMadpfwh9y5qo3qneTftWtXa6WXTJky6ahRo1KryokcOXJEfX19tVatWrpo0SIdMWKEZs6c2ZpbsWrVKq1SpYoOGjTIus/Ro0e1aNGixq38T6KCBQtavYTOk/Dbt29rpkyZrN6Q8+fP6y+//GJb5cXpSQ6QKeHuYPPpp5+qq6urtmjRQjdt2mS7kGnx4sW1W7du1vjuex3ot2zZYnvMh2lFS8uLmvwTlqBPbtu2bdP69evbrkX3888/a3BwsFaqVOlvF7TBHan5OUvLIWXFihXqcDh0woQJ2r17d3U4HLbf9xEjRmju3Lltw+/vnnuVnL8FjRs31g4dOth67c+fP6/u7u7av39/vXz5soaGhmpAQIDu37/fdt+UPO7dvn1ba9WqpRUrVtSvv/5aL168qNWrV9fPP/880eUokvP1cl749e4ey/j4eD116pSWK1fOGgIXERGhHTt21OzZs+t3332nmzdvTpXrA6naf8+cPbARERH6zDPPaJ06dWzD53bt2qUZMmSwLhLrfD1jYmJ03759+vrrrycabve4UiL8/tP96wKUk/NAtHXrVq1fv77tAl1OW7du1S+//NJ2UbG08KM+b948LVKkiG0Vr/nz52vu3Lmtlq1x48apl5eXVq5cWQcMGKB58+bVZs2a/aNbdefMmaOZM2e2XUV8x44dWqRIkXsu9JGSkyP/aa5cuaLBwcG2ixEmbCX94YcfNF26dDpx4kTdt2+fXrp0ST/66CMdPXp0ooVK/mkLdRDEzUydOlUrVqyon332mXUbcw/NpebnLK2HlFmzZmmXLl3U09NTN27caKvDoUOH9Omnn9auXbsmul9KHIvOnTun+fPnTzQ8qXjx4pojRw4tU6aMrlixIk0MI7906ZKGhoZqpUqVNH/+/NqzZ0/b9uQOdNevX9fq1atrr169VPXO8N+E19L873//qx4eHrYevcuXL+uMGTNsQ/1SS3R0tPbt21eLFy9ura544sQJbd++vW0Y6/bt27VgwYKJAvO9zk+S+pyF36tH968NUAm9++676uPjo2PHjtXvv//+nit+pObJ9smTJ7V69erWEMJXX31VfXx8VNX+4a9cubK2adNGVe+0Hm3btk1ffvllbdGiRapdwDclxcXFaf369bVkyZL66quv6sqVK9Xf31/r16+fKkMg/mmuXLmizz77rB4/flyvX7+uefLk0Y4dO+rmzZu1Zs2aOmTIENt3ZOzYsVq2bFn19vbW4sWLa/78+bVGjRpar149a7IqAfbf688//9SgoCBt2bJlmu5RxL2l5ZASHx+vPXr0sA3Pv3Llik6fPl03bNigq1evtl0CIaUNGzZM69WrZy3SsHLlSq1fv75+/PHH1qIMqmnj+BgfH69nzpyxBeCUrFf79u21fPnyWrVqVXU4HImGrYaEhOiwYcNSrD6mfvzxR/X09NSaNWvq2rVr9fjx49brdvLkSW3durV6e3vrmjVr9MyZM5onT56/vShsWvgswO5fHaCcH8hLly5Z1zrw8vJK0YmaDzJkyBDNkCGDNm3a1OoJW7Zsmbq7u1utFc55IPP+r707D8qyav8A/n3YRCwoZNFSQcUFMQaREUmRzS1F1FTGJWQyNwIdIBiVcmlegQFcQMABLSSEYRFzqFwIhWbQSQJDisk1UnBBUFlklYfn/P5guAW130u9wgP4/fyFt/eD5zg3nPs61znXOXxYDB8+/P+dUejvLyq1tbXiiy++ENOnTxempqbCy8tL2U3qk172nJSVlYmRI0dKZ2cdOXJEuLu7Cy0tLbFy5UppWWR7tSCFQiHu378vzp49K5WLLyoqEu+//36n2Wp6fRUUFLzW5zr1Zb09SFm2bJmYMWOGyM7OFjk5OcLa2lqYmZl1yoAra2xvbGwUBgYGQldXVyxbtkxoaGh0yub3VsqYSG4vKmBmZiaNPUK07evOzMyUyrwrcyVD+ztXx3dGNzc3sWnTJume9vLvHTk7O4tp06aJWbNmidmzZwu5XN7v39H6k9c6gHre7du3ld0EycGDB4Wenp6QyWQvpPqLi4vFnDlzxOLFiztd9/T0FPPnzxctLS3dVlK0r6irq+u09pm/lP6djoNleXm5GD9+vDh69Kh07dtvv+10yLQQQpw4cUJkZ2e/9Pvl5uaKSZMmdTp8kYj6pt4cpJSWlgoTExNhYWEhRowYITZv3qyUdvydEydOiDFjxojg4OBORxww0/CinJwcMXLkSCkL1tzcLHx9fUVoaKjYv3+/0s7/6+j+/ftSkKRQKMSUKVOEtbW1+P3334Wzs7Nwc3OT9o61v49cu3ZNBAQECJlMJpydnZXVdPqXGEC9hLJmMhQKhaivrxdWVlbC0NBQJCcnCwsLC7F69epOa8kVCoVIS0sTOjo6wsvLS5w8eVKkp6eLESNGSIflvu7aB6GXnVNEL3r+/yg/P1/Y29uL4ODgTsGRo6Oj+Pjjj6U///DDD2L8+PEiNzdXVFdXi5iYGDFkyBARFBTU6Xu2f33nzh1x586dbu4NEfWE3h6kVFVVievXr3daftZbJtMUCoWYNGmS8PHxkV6s+9t+0FelsbFR6OjoiOnTpwtvb28xduxYMWrUKKmISU97fkJaLpeL+fPnCxsbGxETEyOEaCvm5e7uLoYMGSLs7e07TdB3rB4rl8tfeYEI6hkMoHqJji+b33//vbSZOisrS8hkshfKnioUCnH8+HExefJkMWHCBDF06NAXDowj6oqXDdo//vij8PDwECYmJsLZ2VlcuXJFCCGEj4+PcHFxkQL6wsJC4eLiIvT09MTEiRPFiBEjOi2zIKL+rTcHKR31xsm0oqIiYWRkJJKSkpTdlF4vNzdX+Pn5iaVLl/aao0Y6FvKqqakRgYGBYvjw4VLBiJ9//lkYGxt3ypBlZ2dLZdaf1xt/bujvyYQQAqRUgYGBePjwId577z2sWbNGui6Xy6GmpoaFCxeivLwcp0+fhq6ubqfPtrS04Pbt2zA2NoaamhoAQKFQQEVFpUf7QH3b06dPER0dDQMDA5iamsLS0hIA8ODBA7i6ukJHRwd79+7FmTNnkJiYiLy8POmztbW1KCoqQk1NDZydnaXrfA6JXi8KhQIymQwymUzZTekzli5dioULF8LNzU3ZTekThBBKeb7axzOFQoHW1lYEBgbi0KFDyMrKgpmZGQDg9u3bCAgIQENDA06cOIGioiK4uroiMDAQc+fORWZmJvz9/TF37lxERERAXV29x/tBrw7fbpTowYMHmDNnDhITE1FaWoq1a9ciKCgI9fX1ACD9koiOjkZhYSEiIyNx9+5dXL58GQDQ2toKdXV1mJiYQE1NDa2trQDAl1bqkva5k7S0NOjr6yMhIQEhISGwsbHBoUOH8PDhQxgaGuLAgQMYOnQo5syZg4aGBvzxxx8oLS0F0DaoaGtrw9bWVgqe5HI5AD6HRK8bFRUVBk//UGpqKoOnf0BZz5eKigqqqqpw9+5dqKurY8mSJZg0aRIWL16M7OxsAICRkREGDx4svcMNGjQI9vb2cHd3h4ODAzw8PODt7Y2DBw8yeOoHmIFSgpaWFixYsAATJkyAEAIhISHQ0NDA4cOHsWXLFiQmJmLevHkAnmWhwsPDER8fj9LSUmhra+PKlSsYOHCgkntCfUFjY6P0rDw/e/fkyRPMnDkTixYtwrZt29DU1ITg4GCkp6dj69atnQb2VatW4cKFC6isrMSZM2dga2vb430hIiLqbi/LdG3cuBH5+flYvnw5/P39IYSAnZ0dAODTTz/F8uXLsWfPHnz11Ve4evUqAKCpqQmFhYWoqKjAvHnzpMCptbUVqqqqPdspeqU4RdyDmpubkZSUBHV1dRgbGyM8PBwDBgyAhoYGAGDdunUYP348YmNjUVZWBuDZLL63tzfS09ORlpaGW7duMXii/6q8vBwuLi5wd3dHfHw8gBdn7/Lz81FaWgoHBwcAgKamJnbt2gVjY2OcOXMG9+/fl+6NjIyEr68vWlpacO3atR7rBxERUU9oX6LXPlb+8ssv0t9FRUXB29sb8fHxiIuLg0wmQ1RUFExNTbF27Vrk5+fjxo0bmDFjBoC2IElTUxM2NjZYuHAh1NXVpRUaDJ76PgZQPejYsWPw9PRESkoKIiMj8eabb6Kurg6NjY3SPXv37kVOTg7Onj0LuVwurbkFABMTE8ycORPAs2VSRH+noKAAMpkMWlpaWLNmDcLCwlBeXg6gLQsKAIMHD0ZFRQUMDAwAtGWrZDIZ1q5di8zMTCmAF0JAV1cXmzdvxoYNGxAWFobKykrldIyIiOgVEkJI71yqqqq4evUqsrKyMHXqVGRmZgKAtCf9ww8/xJ49eyCEgLm5OcLDwzFr1ix4enoiIyMD7777LoCXB0nte9Wp72MA1c1qa2ulrz/66CPY2dkhMTERjY2NCAsLQ0JCAoqLi6V7bGxs4OLigoMHD0qz/C/bS8IfQvpvnJ2dkZGRgfj4eERGRiI2NhY+Pj4AIC0jGDVqFCwtLbFz504AbRkoABg2bBgaGhqkDFTHzNWXX36JmzdvIjQ0tCe7Q0RE9Mq1Z5zU1NRQX18PX19fTJgwAcXFxfjggw+wZcsW6V5tbW3MmjULWlpaOHHiBABg4MCBSEpKwrhx49DY2ChNdFP/xgCqG23evBkBAQF4/PixdM3X1xfXr1/H4cOHsX79egwdOhQRERGoqamR7tm7dy9KSkpw/PhxaTMit6pRVwghpIxlx689PDygqamJ1NRUbNy4EefPnwcADBgwAN7e3khKSsLx48dRXV0NoK2whK2tLSZOnPjCv6Grq4vk5GQsWbKkZzpFRETUTdozRYGBgdDT00N4eDgGDRqEMWPGYOfOnSgrK0NkZKR0v6mpKerr66WJSLlcDi0tLezfvx8PHjzAtGnTlNIP6lkMoLrRkiVLkJWVhYsXL0rX7Ozs4ODggLS0NPz11184fPgw0tLSkJubC9F2LhcMDQ3h7e2NhIQE/PrrrwCUV3mG+haZTAYVFRU0NzdDCAEVFRWpOqOtrS1sbGxw8+ZNbNq0Cfn5+dDQ0MCqVavg5+eHDRs2wMnJCTY2NlKA/3eZTldXV0ydOrUnu0ZERPTKNTc345NPPkFcXByOHDmCU6dOYcqUKQgJCcGtW7ewbds2bN++HU1NTQDalr5XV1dLk+Pt46Senh40NTWlMZf6NwZQ3cjOzg5jx45FcnKyVBQCAHbt2oXr169j3759sLKywrhx47B7925p9h8Atm/fjqqqKsTGxqKurk4Jrae+4vlf1ikpKXB2dsajR48ghICqqipUVFRQUlICe3t7xMXFYcyYMXB1dUVycjIAIDQ0FMeOHYO7uzsWLVqEiooKZpiIiKjfq62txfnz5+Hp6Ynly5dj7ty5SElJgb6+PtLT02FnZwdjY2OsXr0at27dwnfffQcjIyOpWvLzWCDi9cAy5t3s3r17sLa2xu7du+Hu7i5dHzduHCoqKjBq1CgEBATAyMgIVlZWAJ6VLs/Ozoauri4sLCyU1Hrqi7y8vGBgYIAdO3YAeHYA4I4dO5CZmSkdgrtmzRoUFBRg9uzZ2LNnzwvfp/05JCIi6q8uX74MR0dHpKenw9HRURoz4+LiEB4ejqioKAwYMADLli2Djo4O/vzzT/znP//BZ599puymkxIxA9XN3nnnHbi5ueHo0aPIysoCAJw8eRLGxsbYv38/tm7diiVLlsDKykra59T+0uro6MjgiV6qY9appqYG8+fPR0lJCQDgwoULmDx5MgBIy/iAtkP9tLW1pep5+/btg4+PD06dOvVCRT0hBIMnIiLq9ywsLKCtrY3Tp08DeLbn3M3NDTdu3EBjYyOsra2Rl5eHmJgYlJWVMXgiZqB6QlNTE4yMjCCXy+Hk5ISMjAzs3r0b/v7+ym4a9TEdD99raGjAzZs3oaenBwcHB5iZmSE6Ohqmpqa4dOkSRo8e3ekzqamp8Pb2lirrveygQCIiotdNTEwMfH19cfHiRZibmwNoOydxxYoV+Oabb14oDNHa2goVFRWOoa8xZqB6gKamJmJjYzF48GBYWlqitLRUCp4Yv9I/0R48BQcHY/jw4UhISICqqioiIiKQkZEBPz8/1NbWwsfHB1u2bEFFRYX0mdGjR0NNTe2lhUl4rhgREb2u1q9fD1tbW6xYsQL+/v44efIkPDw8MHr0aCmg6khVVZXB02uOGageIoTA5MmTYW9vj8DAQAwcOJB7TOgfq6qqwooVK1BSUoKgoCDY2tpCX18fDQ0N8Pf3R2xsLHbu3AlDQ0MEBQVBU1MTrq6ucHV1RXNzMw4cOICoqCjo6OgouytERES9xpMnTxAaGoqffvoJjx49gpOTU6fy5UQdMYDqQb/99htcXFwQFBSElStXKrs51AdduHABPj4+iIqKwpQpU3Dnzh0MGzYMQggUFhbCyckJn3/+Ofz8/HDv3j2cO3cOYWFhUCgUyMvLw6BBg5TdBSIiol6rvr4ecrlcmmjsuHSeqB2X8PUgc3NzWFlZ8YwA+teqqqpQUFCA7OxsrFu3DiNGjEBeXh5kMhksLS3h5eWFkJAQ1NXVSQVMzp07h+LiYil4aj9cl4iIiDrT0tKCjo4OFAqFdBQI0fOYgephnMmg/1V0dDQuXbqE06dPIyUlBXZ2dgCAyspKPHz4EHZ2dliwYAG+/vrrTp/jklEiIiKi/x0DKKI+RgiBDRs24O2330ZISAiAtlLm8fHxMDc3x9OnT6GnpyeVMiciIiKiV4fT0UR9jEwmQ3V1Na5du4acnBzIZDJs3boVdXV1SE1NhZmZGQCWKSciIiLqDsxAEfVBZWVlcHR0xBtvvIHHjx9j0aJFiIiIUHaziIiIiPo9BlBEfVR1dTUqKyvx1ltvQV9fHwD32BERERF1NwZQRP2AQqGATCbjkj0iIiKibsYAioiIiIiIqIt4DhQREREREVEXMYAiIiIiIiLqIgZQREREREREXcQAioiIiIiIqIsYQBEREREREXURAygiIiIiIqIuYgBFRERERETURQygiIiIiIiIuogBFBERERERURcxgCIiIiIiIuqi/wPlbIeZ6Nm9uQAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"markdown","source":"# **Creating Datasets**","metadata":{}},{"cell_type":"code","source":"class TweetDataset(Dataset):\n    def __init__(self, texts ,tokenizer , labels=None):\n        \n        self.input_ids = [tokenizer.encode(text) for text in texts]\n        self.labels = labels\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx): \n        \n        indices = torch.tensor(self.input_ids[idx])\n        labels = torch.tensor(self.labels[idx])\n        att_masks = [int(token_id > 0) for token_id in indices]\n        \n        if self.labels is not None:\n            return (indices,att_masks,labels)\n        \n        return indices,att_masks","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.449411Z","iopub.execute_input":"2024-03-08T14:13:45.449860Z","iopub.status.idle":"2024-03-08T14:13:45.461711Z","shell.execute_reply.started":"2024-03-08T14:13:45.449820Z","shell.execute_reply":"2024-03-08T14:13:45.460250Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 45):\n\n    #For consistency in results we use a deterministic way to control the source of random number generator\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.463068Z","iopub.execute_input":"2024-03-08T14:13:45.463453Z","iopub.status.idle":"2024-03-08T14:13:45.482320Z","shell.execute_reply.started":"2024-03-08T14:13:45.463423Z","shell.execute_reply":"2024-03-08T14:13:45.480934Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"set_seed()","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.483945Z","iopub.execute_input":"2024-03-08T14:13:45.484332Z","iopub.status.idle":"2024-03-08T14:13:45.499659Z","shell.execute_reply.started":"2024-03-08T14:13:45.484300Z","shell.execute_reply":"2024-03-08T14:13:45.498476Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def custom_collate(batch) :\n    \n    inputs = [torch.tensor(item[0]) for item in batch]  # Extract input sequences\n    # Perform padding on input sequences\n    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n    att_masks = [[int(token_id > 0) for token_id in input] for input in padded_inputs]\n    targets = [item[2] for item in batch]  # Extract targets\n\n    return (padded_inputs,torch.tensor(att_masks),torch.tensor(targets))   ","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.501266Z","iopub.execute_input":"2024-03-08T14:13:45.502124Z","iopub.status.idle":"2024-03-08T14:13:45.511028Z","shell.execute_reply.started":"2024-03-08T14:13:45.502091Z","shell.execute_reply":"2024-03-08T14:13:45.509895Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def create_loaders(tokenizer,X,Y,custom_collate,batch,test_loader=True) :\n            \n    if test_loader:\n        \n        #Splitting into Training (70), Validation & Test Set (15 each)\n        \n        train_X, remaining_X ,train_Y, remaining_Y = train_test_split(X, Y, test_size=0.3, random_state=28)\n        val_X, test_X , val_Y, test_Y = train_test_split(remaining_X, remaining_Y, test_size=0.5, random_state=28)\n        \n        train_set = TweetDataset(train_X.values.flatten(), tokenizer, train_Y)\n        train_loader = DataLoader(train_set, batch_size = batch ,shuffle=False, collate_fn=custom_collate)\n\n        val_set = TweetDataset(val_X.values.flatten() ,tokenizer ,val_Y)\n        val_loader = DataLoader(val_set, batch_size = batch,shuffle=False, collate_fn=custom_collate)\n\n        test_set = TweetDataset(test_X.values.flatten() ,tokenizer, test_Y)\n        test_loader = DataLoader(test_set, batch_size = batch ,shuffle=False, collate_fn=custom_collate)\n        \n        return (train_loader,val_loader,test_loader)\n    \n    #Splitting into Training (80) & Validation (20) if no test loader was asked\n\n    train_X, val_X ,train_Y, val_Y = train_test_split(final_df['Text'], labels, test_size=0.2, random_state=28)\n\n    train_set = TweetDataset(train_X.values.flatten(),tokenizer, train_Y.values.flatten())\n    train_loader = DataLoader(train_set, batch_size = batch ,shuffle=False, collate_fn=custom_collate)\n\n    val_set = TweetDataset(val_X.values.flatten(),tokenizer, val_Y.values.flatten())\n    val_loader = DataLoader(val_set, batch_size = batch ,shuffle=False, collate_fn=custom_collate)\n\n    return (train_loader,val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.515169Z","iopub.execute_input":"2024-03-08T14:13:45.515877Z","iopub.status.idle":"2024-03-08T14:13:45.528385Z","shell.execute_reply.started":"2024-03-08T14:13:45.515843Z","shell.execute_reply":"2024-03-08T14:13:45.527208Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class GRBert(nn.Module):\n  def __init__(self, dropout, hidden, activation,pretrained_path,output_dim):\n    super(GRBert, self).__init__()\n    \n    self.pretrained = AutoModel.from_pretrained(pretrained_path)\n    self.dropout = nn.Dropout(dropout) \n    self.linear = nn.Sequential(\n          nn.Linear(768, hidden, device=device),   #Model follows English Bert Model having 768 hidden layers \n          activation(),\n\t\t  nn.Dropout(dropout),\n          nn.Linear(hidden,output_dim, device=device),\n        )\n    # Freeze pretrained layer to speed up computations\n    for param in self.pretrained.parameters():\n        param.requires_grad = False\n        \n  def forward(self, ids, mask):\n    output = self.pretrained(ids, mask)\n    return self.dropout(self.linear(output[0][:, 0, :]))\n   \n\n  def predict(loader, neural):\n    neural.eval()\n    all_preds = []\n    with torch.no_grad():\n        for batch in loader:\n            X = batch[0].to(device)\n            att_mask = batch[1].to(device)\n            pred = neural(X,att_mask)\n            # Accumulate predictions and labels for computing metrics after all batches\n            all_preds.extend(pred.argmax(1).cpu().tolist())\n\n    return all_preds","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.529749Z","iopub.execute_input":"2024-03-08T14:13:45.530085Z","iopub.status.idle":"2024-03-08T14:13:45.546233Z","shell.execute_reply.started":"2024-03-08T14:13:45.530057Z","shell.execute_reply":"2024-03-08T14:13:45.545144Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# **Testing**","metadata":{}},{"cell_type":"code","source":"def evaluation(loader, loss_func, neural):\n    neural.eval()\n    total_error = 0\n    total_correct = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in loader:\n            # `batch` contains three PyTorch tensors:\n            #   [0]: input ids \n            #   [1]: attention masks\n            #   [2]: labels \n            X = batch[0].to(device)\n            att_mask = batch[1].to(device)\n            label = batch[2].to(device)\n            pred = neural(X, att_mask)\n            total_correct += (pred.argmax(1) == label.squeeze()).sum().item()\n            total_error += loss_func(pred, label).item()\n\n            # Accumulate predictions and labels for computing metrics after all batches\n            all_preds.extend(pred.argmax(1).cpu().tolist())\n            all_labels.extend(label.cpu().tolist())\n\n    avg_error = total_error / len(loader.dataset)\n    f1_macro = f1_score(all_labels, all_preds, average='macro')\n    accuracy = total_correct / len(loader.dataset) * 100\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n\n    return avg_error, f1_macro, accuracy, conf_matrix, all_preds","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.547752Z","iopub.execute_input":"2024-03-08T14:13:45.548704Z","iopub.status.idle":"2024-03-08T14:13:45.565141Z","shell.execute_reply.started":"2024-03-08T14:13:45.548671Z","shell.execute_reply":"2024-03-08T14:13:45.563797Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"#We do validation in every single epoch so it has to be combined in the training function to evaluate the efficiency of current parameters\ndef train_and_val(epochs,optimizer,train_loader,val_loader,loss_func,neural,patience) :\n\n  best_score = -1\n  continuous = 0\n  train_scores = []\n  train_loss = []\n  val_scores = []\n  val_loss = []   \n    \n  #Iterate through batches for every epoch\n  for epoch in range(epochs) :\n    neural.train()   \n    #iterating through batches\n    for batch in train_loader :\n      # set to zero the parameter gradients\n      optimizer.zero_grad()\n      # `batch` contains three pytorch tensors:\n      #   [0]: input ids \n      #   [1]: attention masks\n      #   [2]: labels \n      X = batch[0].to(device)\n      att_mask = batch[1].to(device)\n      label = batch[2].to(device)\n      pred = neural(X,att_mask)\n      error = loss_func(pred,label.squeeze())\n      # computing gradients/the direction that fits our objective\n      error.backward()  \n      #optimizing weights/slightly adjusting parameters\n      optimizer.step()\n    #compute validation scores for each epoch\n    loss , f1 , acc , cf_matr  , preds = evaluation(val_loader,loss_func,neural)\n    val_scores += [acc]\n    val_loss += [loss]\n    loss , f1 , acc , cf_matr , preds = evaluation(train_loader,loss_func,neural)\n    train_scores += [acc]  \n    train_loss += [loss]\n    if acc > best_score :\n      wanted = neural\n      best_score = acc\n      best_epoch = epoch\n    else :\n      continuous += 1\n      if continuous == patience :\n          return wanted,best_epoch,train_scores,train_loss,val_scores,val_loss\n        \n  return wanted,best_epoch,train_scores,train_loss,val_scores,val_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.566814Z","iopub.execute_input":"2024-03-08T14:13:45.567243Z","iopub.status.idle":"2024-03-08T14:13:45.584609Z","shell.execute_reply.started":"2024-03-08T14:13:45.567172Z","shell.execute_reply":"2024-03-08T14:13:45.583355Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Prints best parameters of study and relevant statistics \ndef showcase(study,path,output_dim,acceptable_labels):\n    \n    # Print the best hyperparameters and their corresponding accuracy\n    best_parameters = study.best_params\n\n    print(\"Best parameters \",best_parameters)\n    train_loader,val_loader,test_loader = create_loaders(tokenizer,final_df['Text'], labels_tensor,custom_collate,best_parameters['batch_size'])\n\n    gr_bert = GRBert(best_parameters['drop'],best_parameters['hidden'],best_parameters['activation_function'],path,output_dim).to(device)\n\n    optimizer = getattr(torch.optim, best_parameters['optimizer'])(gr_bert.parameters(), lr=best_parameters['lr'])\n    loss_func = nn.CrossEntropyLoss()\n    epochs = best_parameters['epochs']\n    patience = best_parameters['patience']\n    output = train_and_val(epochs,optimizer,train_loader,val_loader,loss_func,gr_bert,patience)\n\n    #Performance of best Model\n    print(\"Best epoch is : \",output[1])\n    loss , f1 , best_accuracy , cf_matr , preds = evaluation(test_loader,loss_func,output[0])\n    print(\"F1-score for best model is : \",f1*100 ,\", best  accuracy is \", best_accuracy)\n    \n    plt.figure()\n\n    #Print hyperparameter's importance\n    vis.plot_param_importances(study)\n    \n    plt.show()\n\n    #Plotting the confusion matrix\n    cm_df = pd.DataFrame(cf_matr,index = acceptable_labels, columns = acceptable_labels)\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm_df, annot=True)\n    plt.title('Confusion Matrix')\n    plt.ylabel('Actual Values')\n    plt.xlabel('Predicted Values')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:24:37.151496Z","iopub.execute_input":"2024-03-08T14:24:37.151933Z","iopub.status.idle":"2024-03-08T14:24:37.165494Z","shell.execute_reply.started":"2024-03-08T14:24:37.151899Z","shell.execute_reply":"2024-03-08T14:24:37.164619Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def plot_learning_curve(best_parameters,path,output_dim,train_loader,val_loader) :\n    \n    gr_bert = GRBert(best_parameters['drop'],best_parameters['hidden'],best_parameters['activation_function'],path,output_dim).to(device)\n\n    plt.figure()\n\n    #Train for all epochs\n    epochs = best_parameters['epochs']\n    patience = epochs\n    optimizer = getattr(torch.optim, best_parameters['optimizer'])(gr_bert.parameters(), lr=best_parameters['lr'])\n    loss_func = nn.CrossEntropyLoss()\n    best_model,best_epoch,train_scores,train_loss,val_scores,val_loss = train_and_val(epochs,optimizer,train_loader,val_loader,loss_func,gr_bert,patience)\n\n    epoch_list = range(1, epochs + 1)\n    plt.grid()\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epochs')\n    plt.plot(epoch_list, train_scores, label=\"Train Score\")\n    plt.plot(epoch_list, val_scores, label=\"Validation Score\")\n    plt.legend()  \n    plt.show()    \n    \n    plt.figure()\n    \n    plt.grid()\n    plt.ylabel('Loss')\n    plt.xlabel('Epochs')\n    plt.plot(epoch_list, train_loss, label=\"Training Loss\")\n    plt.plot(epoch_list, val_loss, label=\"Validation Loss\")\n    plt.legend()  \n    plt.show()    ","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.604868Z","iopub.execute_input":"2024-03-08T14:13:45.605986Z","iopub.status.idle":"2024-03-08T14:13:45.620656Z","shell.execute_reply.started":"2024-03-08T14:13:45.605946Z","shell.execute_reply":"2024-03-08T14:13:45.619297Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_output_file(X,tokenizer,custom_collate,path,best_parameters,output_dim,train_loader,val_loader,output_name) :\n\n    #Create Dataset & Dataloader for test_df\n    test_set = TweetDataset(X.values.flatten(), tokenizer)\n    test_loader = DataLoader(test_set, batch_size = best_parameters['batch_size'] ,shuffle=False, collate_fn=custom_collate)\n\n    #Train the model with the entire dataset this time\n    gr_bert = GRBert(best_parameters['drop'],best_parameters['hidden'],best_parameters['activation_function'],path,output_dim).to(device)\n\n    optimizer = getattr(torch.optim, best_parameters['optimizer'])(gr_bert.parameters(), lr=best_parameters['lr'])\n    loss_func = nn.CrossEntropyLoss()\n    epochs = best_parameters['epochs']\n    patience = best_parameters['patience']\n    output = train_and_val(epochs,optimizer,train_loader,val_loader,loss_func,gr_bert,patience)\n\n    #Predict using best model\n    test_pred = output[0].predict(test_loader)\n\n    # Create submission.csv output file\n    with open(output_name, \"w\", newline='') as output_file:\n        # Create a CSV writer\n        submission = csv.writer(output_file)\n\n        # Write the header row\n        submission.writerow([\"Id\", \"Predicted\"])\n\n        # Write the data rows\n        for idx, predicted_value in zip(X['New_ID'], test_pred):\n            submission.writerow([idx, int_to_labels[predicted_value]])    ","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.622493Z","iopub.execute_input":"2024-03-08T14:13:45.623176Z","iopub.status.idle":"2024-03-08T14:13:45.637171Z","shell.execute_reply.started":"2024-03-08T14:13:45.623124Z","shell.execute_reply":"2024-03-08T14:13:45.636118Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# **Experimenting on GreekBERT Model**","metadata":{}},{"cell_type":"markdown","source":"> #   Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"path = \"nlpaueb/bert-base-greek-uncased-v1\"\ntokenizer = AutoTokenizer.from_pretrained(path)\noutput_dim = 3","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:45.638668Z","iopub.execute_input":"2024-03-08T14:13:45.639300Z","iopub.status.idle":"2024-03-08T14:13:48.576934Z","shell.execute_reply.started":"2024-03-08T14:13:45.639269Z","shell.execute_reply":"2024-03-08T14:13:48.575834Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ee80162f60b4ea6a53630d8e9572c06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6906cec870764c69bff7339a5e1b3f0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea18e65f5ba4fe9836dc658f387147c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc18efb5000c4e44b78e60b2dbd1108b"}},"metadata":{}}]},{"cell_type":"code","source":"# Set the logging level to CRITICAL to deactivate messages\noptuna.logging.set_verbosity(optuna.logging.CRITICAL)\n\ndef objective(trial):\n    \n    # Define the search space for model's hyperparameters\n    epoch = trial.suggest_categorical('epochs', [5,10, 15])                                                                        \n    drop = trial.suggest_float('drop', 0.5, 0.8, step=0.1)    \n    batch_size = trial.suggest_categorical('batch_size', [4,8,16,32]) \n    hidden = trial.suggest_int('hidden',50,256,step=2)\n    rate = trial.suggest_float('lr', 1e-6,1e-2,step=1e-3)\n    patience = trial.suggest_categorical('patience', [5, 10,15])\n    opt = trial.suggest_categorical('optimizer', [\"SGD\", \"Adam\", \"Adagrad\", \"Adadelta\", \"Adamax\"])\n    func = trial.suggest_categorical('activation_function', [nn.ReLU, nn.Tanh, nn.LeakyReLU, nn.CELU, nn.Hardshrink])\n    \n    torch.cuda.empty_cache()\n    \n    train_loader,val_loader,test_loader = create_loaders(tokenizer,final_df['Text'], labels_tensor,custom_collate,batch_size)\n    \n    gr_bert = GRBert(drop,hidden,func,path,output_dim).to(device)\n    optimizer = getattr(torch.optim, opt)(gr_bert.parameters(), lr=rate)\n    loss_func = nn.CrossEntropyLoss()\n    output = train_and_val(epoch, optimizer, train_loader, val_loader,loss_func,gr_bert,patience)\n    \n    #Compute the test accuracy of the best model (best validation accuracy out of all epochs) on the test set\n    loss, f1, acc, cf_matr , preds = evaluation(test_loader, loss_func,output[0])\n    \n    del gr_bert\n    \n    return acc  # The accuracy is the metric to be maximized","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:13:48.586721Z","iopub.execute_input":"2024-03-08T14:13:48.587076Z","iopub.status.idle":"2024-03-08T14:13:48.606624Z","shell.execute_reply.started":"2024-03-08T14:13:48.587048Z","shell.execute_reply":"2024-03-08T14:13:48.605532Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')  # maximize accuracy\nstudy.optimize(objective, n_trials=20)\nshowcase(study,path,output_dim,acceptable_labels)\n\n#Best parameters optuna found\nbest_parameters = {\n    'epochs': 2,\n    'drop': 0.6,\n    'batch_size': 8,\n    'hidden': 100,\n    'lr': 0.0001,\n    'patience': 5,\n    'optimizer': \"Adadelta\",\n    'activation_function': nn.ReLU\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:24:43.325600Z","iopub.execute_input":"2024-03-08T14:24:43.326268Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Best parameters  {'epochs': 2, 'drop': 0.6, 'batch_size': 8, 'hidden': 100, 'lr': 0.0001, 'patience': 5, 'optimizer': 'Adadelta', 'activation_function': <class 'torch.nn.modules.activation.ReLU'>}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> #   Metrics & Plots for Best Model:","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\n#Plotting Learning Curve\n\n#Splitting into training & Validation Set Only this time to get a clearer picture of the performances\ntrain_loader,val_loader = create_loaders(tokenizer,final_df['Text'],labels_tensor,custom_collate,best_parameters['batch_size'],False)\n\nplot_learning_curve(best_parameters,path,output_dim,train_loader,val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.629655Z","iopub.status.idle":"2024-03-08T14:18:41.630097Z","shell.execute_reply.started":"2024-03-08T14:18:41.629896Z","shell.execute_reply":"2024-03-08T14:18:41.629913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> #    Predictions","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\ncreate_output_file(test_df['Text'],tokenizer,custom_collate,path,best_parameters,output_dim,train_loader,val_loader,\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.631628Z","iopub.status.idle":"2024-03-08T14:18:41.632023Z","shell.execute_reply.started":"2024-03-08T14:18:41.631832Z","shell.execute_reply":"2024-03-08T14:18:41.631848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Experimenting on DistilGREEK-BERT Model**","metadata":{}},{"cell_type":"markdown","source":"> #   Hyperparmeter Tuning","metadata":{}},{"cell_type":"code","source":"path_distil = \"EftychiaKarav/DistilGREEK-BERT\"\ntokenizer_distil = AutoTokenizer.from_pretrained(path_distil)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.633897Z","iopub.status.idle":"2024-03-08T14:18:41.634320Z","shell.execute_reply.started":"2024-03-08T14:18:41.634107Z","shell.execute_reply":"2024-03-08T14:18:41.634122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the logging level to CRITICAL to deactivate messages\noptuna.logging.set_verbosity(optuna.logging.CRITICAL)\n\ndef objective(trial):\n    \n    # Define the search space for model's hyperparameters\n    epoch = trial.suggest_categorical('epochs', [5,10, 15)                                                                        \n    drop = trial.suggest_float('drop', 0.5, 0.8, step=0.1) \n    batch_size = trial.suggest_categorical('batch_size', [4,8,16,32]) \n    hidden = trial.suggest_int('hidden',50,256,step=2)\n    rate = trial.suggest_float('lr', 1e-6,1e-2,step=1e-3)\n    patience = trial.suggest_categorical('patience', [5, 10,15])\n    opt = trial.suggest_categorical('optimizer', [\"SGD\", \"Adam\", \"Adagrad\", \"Adadelta\", \"Adamax\"])\n    func = trial.suggest_categorical('activation_function', [nn.ReLU, nn.Tanh, nn.LeakyReLU, nn.CELU, nn.Hardshrink])\n    \n    torch.cuda.empty_cache()\n    \n    train_loader,val_loader,test_loader = create_loaders(tokenizer_distil,final_df['Text'], labels_tensor,custom_collate,batch_size)\n    \n    gr_bert = GRBert(drop,hidden,func,path_distil,output_dim).to(device)\n    optimizer = getattr(torch.optim, opt)(gr_bert.parameters(), lr=rate)\n    loss_func = nn.CrossEntropyLoss()\n    output = train_and_val(epoch, optimizer, train_loader, val_loader,loss_func,gr_bert,patience)\n    \n    #Compute the test accuracy of the best model (best validation accuracy out of all epochs) on the test set\n    loss, f1, acc, cf_matr , preds = evaluation(test_loader, loss_func,output[0])\n​\n    del gr_bert\n\n    return acc  # The accuracy is the metric to be maximized","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.635657Z","iopub.status.idle":"2024-03-08T14:18:41.636059Z","shell.execute_reply.started":"2024-03-08T14:18:41.635871Z","shell.execute_reply":"2024-03-08T14:18:41.635886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# study = optuna.create_study(direction='maximize')  # maximize accuracy\n# study.optimize(objective, n_trials=20)# Run optimization for 30 trials\n# showcase(study,path_distil,output_dim,acceptable_labels)\n\n#Best parameters optuna found\nbest_parameters_distil = {\n    'epochs': 15,\n    'drop': 0.6,\n    'batch_size': 8,  \n    'hidden': 100,\n    'lr': 0.0001,\n    'patience': 5,\n    'optimizer': \"Adadelta\",\n    'activation_function': nn.ReLU\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.637920Z","iopub.status.idle":"2024-03-08T14:18:41.638964Z","shell.execute_reply.started":"2024-03-08T14:18:41.638650Z","shell.execute_reply":"2024-03-08T14:18:41.638678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> #   Metrics & Plots for Best Model:","metadata":{}},{"cell_type":"code","source":"#Plotting Learning Curve\ntorch.cuda.empty_cache()\n\n#Splitting into training & Validation Set Only this time to get a clearer picture of the performances\ntrain_loader,val_loader = create_loaders(tokenizer_distil,final_df['Text'],labels_tensor,custom_collate,best_parameters_distil['batch_size'],False)\n\nplot_learning_curve(best_parameters_distil,path,output_dim,train_loader,val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.640596Z","iopub.status.idle":"2024-03-08T14:18:41.641253Z","shell.execute_reply.started":"2024-03-08T14:18:41.640947Z","shell.execute_reply":"2024-03-08T14:18:41.640970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> #    Predictions :","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\n#As the assignment requests we only produce predictions for GREEK-BERT \ncreate_output_file(test_df['Text'],tokenizer_distil,custom_collate,path_distil,best_parameters_distil,output_dim,train_loader,val_loader,\"submission_distil.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:18:41.642923Z","iopub.status.idle":"2024-03-08T14:18:41.643502Z","shell.execute_reply.started":"2024-03-08T14:18:41.643208Z","shell.execute_reply":"2024-03-08T14:18:41.643230Z"},"trusted":true},"execution_count":null,"outputs":[]}]}